// Generated by dts-bundle-generator v9.3.1

/**
 * Minimal `EventEmitter` interface that is molded against the Node.js
 * `EventEmitter` interface.
 */
export declare class EventEmitter<EventTypes extends EventEmitter.ValidEventTypes = string | symbol, Context extends any = any> {
	static prefixed: string | boolean;
	/**
	 * Return an array listing the events for which the emitter has registered
	 * listeners.
	 */
	eventNames(): Array<EventEmitter.EventNames<EventTypes>>;
	/**
	 * Return the listeners registered for a given event.
	 */
	listeners<T extends EventEmitter.EventNames<EventTypes>>(event: T): Array<EventEmitter.EventListener<EventTypes, T>>;
	/**
	 * Return the number of listeners listening to a given event.
	 */
	listenerCount(event: EventEmitter.EventNames<EventTypes>): number;
	/**
	 * Calls each of the listeners registered for a given event.
	 */
	emit<T extends EventEmitter.EventNames<EventTypes>>(event: T, ...args: EventEmitter.EventArgs<EventTypes, T>): boolean;
	/**
	 * Add a listener for a given event.
	 */
	on<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn: EventEmitter.EventListener<EventTypes, T>, context?: Context): this;
	addListener<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn: EventEmitter.EventListener<EventTypes, T>, context?: Context): this;
	/**
	 * Add a one-time listener for a given event.
	 */
	once<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn: EventEmitter.EventListener<EventTypes, T>, context?: Context): this;
	/**
	 * Remove the listeners of a given event.
	 */
	removeListener<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn?: EventEmitter.EventListener<EventTypes, T>, context?: Context, once?: boolean): this;
	off<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn?: EventEmitter.EventListener<EventTypes, T>, context?: Context, once?: boolean): this;
	/**
	 * Remove all listeners, or those of the specified event.
	 */
	removeAllListeners(event?: EventEmitter.EventNames<EventTypes>): this;
}
export declare namespace EventEmitter {
	export interface ListenerFn<Args extends any[] = any[]> {
		(...args: Args): void;
	}
	export interface EventEmitterStatic {
		new <EventTypes extends ValidEventTypes = string | symbol, Context = any>(): EventEmitter<EventTypes, Context>;
	}
	/**
	 * `object` should be in either of the following forms:
	 * ```
	 * interface EventTypes {
	 *   'event-with-parameters': any[]
	 *   'event-with-example-handler': (...args: any[]) => void
	 * }
	 * ```
	 */
	export type ValidEventTypes = string | symbol | object;
	export type EventNames<T extends ValidEventTypes> = T extends string | symbol ? T : keyof T;
	export type ArgumentMap<T extends object> = {
		[K in keyof T]: T[K] extends (...args: any[]) => void ? Parameters<T[K]> : T[K] extends any[] ? T[K] : any[];
	};
	export type EventListener<T extends ValidEventTypes, K extends EventNames<T>> = T extends string | symbol ? (...args: any[]) => void : (...args: ArgumentMap<Exclude<T, string | symbol>>[Extract<K, keyof T>]) => void;
	export type EventArgs<T extends ValidEventTypes, K extends EventNames<T>> = Parameters<EventListener<T, K>>;
	export const EventEmitter: EventEmitterStatic;
}
declare type RgbColor = {
	r: number;
	g: number;
	b: number;
};
declare type HslColor = {
	h: number;
	s: number;
	l: number;
};
declare type HsvColor = {
	h: number;
	s: number;
	v: number;
};
declare type WithAlpha<O> = O & {
	a: number;
};
declare type RgbaColor = WithAlpha<RgbColor>;
declare type HslaColor = WithAlpha<HslColor>;
declare type HsvaColor = WithAlpha<HsvColor>;
/**
 * Pixi supports multiple color formats, including CSS color strings, hex, numbers, and arrays.
 *
 * When providing values for any of the color properties, you can use any of the {@link color.ColorSource} formats.
 * ```typescript
 * import { Color } from 'pixi.js';
 *
 * // All of these are valid:
 * sprite.tint = 'red';
 * sprite.tint = 0xff0000;
 * sprite.tint = '#ff0000';
 * sprite.tint = new Color('red');
 *
 * // Same for graphics fill/stroke colors and other  color values:
 * graphics.fill({ color: 'red' });
 * graphics.fill({ color: 0xff0000 });
 * graphics.stroke({ color: '#ff0000' });
 * graphics.stroke({ color: new Color('red')};
 * ```
 * @namespace color
 */
/**
 * RGBA color array.
 *
 * `[number, number, number, number]`
 * @memberof color
 */
export type RgbaArray = [
	number,
	number,
	number,
	number
];
/**
 * Valid formats to use when defining any color properties, also valid for the {@link color.Color} constructor.
 *
 * These types are extended from [colord](https://www.npmjs.com/package/colord) with some PixiJS-specific extensions.
 *
 * Possible value types are:
 * - [Color names](https://www.w3.org/TR/css-color-4/#named-colors):
 *   `'red'`, `'green'`, `'blue'`, `'white'`, etc.
 * - RGB hex integers (`0xRRGGBB`):
 *   `0xff0000`, `0x00ff00`, `0x0000ff`, etc.
 * - [RGB(A) hex strings](https://www.w3.org/TR/css-color-4/#hex-notation):
 *   - 6 digits (`RRGGBB`): `'ff0000'`, `'#00ff00'`, `'0x0000ff'`, etc.
 *   - 3 digits (`RGB`): `'f00'`, `'#0f0'`, `'0x00f'`, etc.
 *   - 8 digits (`RRGGBBAA`): `'ff000080'`, `'#00ff0080'`, `'0x0000ff80'`, etc.
 *   - 4 digits (`RGBA`): `'f008'`, `'#0f08'`, `'0x00f8'`, etc.
 * - RGB(A) objects:
 *   `{ r: 255, g: 0, b: 0 }`, `{ r: 255, g: 0, b: 0, a: 0.5 }`, etc.
 * - [RGB(A) strings](https://www.w3.org/TR/css-color-4/#rgb-functions):
 *   `'rgb(255, 0, 0)'`, `'rgb(100% 0% 0%)'`, `'rgba(255, 0, 0, 0.5)'`, `'rgba(100% 0% 0% / 50%)'`, etc.
 * - RGB(A) arrays:
 *   `[1, 0, 0]`, `[1, 0, 0, 0.5]`, etc.
 * - RGB(A) Float32Array:
 *   `new Float32Array([1, 0, 0])`, `new Float32Array([1, 0, 0, 0.5])`, etc.
 * - RGB(A) Uint8Array:
 *   `new Uint8Array([255, 0, 0])`, `new Uint8Array([255, 0, 0, 128])`, etc.
 * - RGB(A) Uint8ClampedArray:
 *   `new Uint8ClampedArray([255, 0, 0])`, `new Uint8ClampedArray([255, 0, 0, 128])`, etc.
 * - HSL(A) objects:
 *   `{ h: 0, s: 100, l: 50 }`, `{ h: 0, s: 100, l: 50, a: 0.5 }`, etc.
 * - [HSL(A) strings](https://www.w3.org/TR/css-color-4/#the-hsl-notation):
 *   `'hsl(0, 100%, 50%)'`, `'hsl(0deg 100% 50%)'`, `'hsla(0, 100%, 50%, 0.5)'`, `'hsla(0deg 100% 50% / 50%)'`, etc.
 * - HSV(A) objects:
 *   `{ h: 0, s: 100, v: 100 }`, `{ h: 0, s: 100, v: 100, a: 0.5 }`, etc.
 * - {@link color.Color} objects.
 * @since 7.2.0
 * @memberof color
 */
export type ColorSource = string | number | number[] | Float32Array | Uint8Array | Uint8ClampedArray | HslColor | HslaColor | HsvColor | HsvaColor | RgbColor | RgbaColor | Color | number;
/**
 * Color utility class. Can accept any {@link color.ColorSource} format in its constructor.
 * ```js
 * import { Color } from 'pixi.js';
 *
 * new Color('red').toArray(); // [1, 0, 0, 1]
 * new Color(0xff0000).toArray(); // [1, 0, 0, 1]
 * new Color('ff0000').toArray(); // [1, 0, 0, 1]
 * new Color('#f00').toArray(); // [1, 0, 0, 1]
 * new Color('0xff0000ff').toArray(); // [1, 0, 0, 1]
 * new Color('#f00f').toArray(); // [1, 0, 0, 1]
 * new Color({ r: 255, g: 0, b: 0, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * new Color('rgb(255, 0, 0, 0.5)').toArray(); // [1, 0, 0, 0.5]
 * new Color([1, 1, 1]).toArray(); // [1, 1, 1, 1]
 * new Color([1, 0, 0, 0.5]).toArray(); // [1, 0, 0, 0.5]
 * new Color(new Float32Array([1, 0, 0, 0.5])).toArray(); // [1, 0, 0, 0.5]
 * new Color(new Uint8Array([255, 0, 0, 255])).toArray(); // [1, 0, 0, 1]
 * new Color(new Uint8ClampedArray([255, 0, 0, 255])).toArray(); // [1, 0, 0, 1]
 * new Color({ h: 0, s: 100, l: 50, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * new Color('hsl(0, 100%, 50%, 50%)').toArray(); // [1, 0, 0, 0.5]
 * new Color({ h: 0, s: 100, v: 100, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * ```
 * @since 7.2.0
 * @memberof color
 */
export declare class Color {
	/**
	 * Default Color object for static uses
	 * @example
	 * import { Color } from 'pixi.js';
	 * Color.shared.setValue(0xffffff).toHex(); // '#ffffff'
	 */
	static readonly shared: Color;
	/**
	 * Temporary Color object for static uses internally.
	 * As to not conflict with Color.shared.
	 * @ignore
	 */
	private static readonly _temp;
	/** Pattern for hex strings */
	private static readonly HEX_PATTERN;
	/** Internal color source, from constructor or set value */
	private _value;
	/** Normalized rgba component, floats from 0-1 */
	private _components;
	/** Cache color as number */
	private _int;
	/** An array of the current Color. Only populated when `toArray` functions are called */
	private _arrayRgba;
	private _arrayRgb;
	/**
	 * @param {ColorSource} value - Optional value to use, if not provided, white is used.
	 */
	constructor(value?: ColorSource);
	/** Get red component (0 - 1) */
	get red(): number;
	/** Get green component (0 - 1) */
	get green(): number;
	/** Get blue component (0 - 1) */
	get blue(): number;
	/** Get alpha component (0 - 1) */
	get alpha(): number;
	/**
	 * Set the value, suitable for chaining
	 * @param value
	 * @see Color.value
	 */
	setValue(value: ColorSource): this;
	/**
	 * The current color source.
	 *
	 * When setting:
	 * - Setting to an instance of `Color` will copy its color source and components.
	 * - Otherwise, `Color` will try to normalize the color source and set the components.
	 *   If the color source is invalid, an `Error` will be thrown and the `Color` will left unchanged.
	 *
	 * Note: The `null` in the setter's parameter type is added to match the TypeScript rule: return type of getter
	 * must be assignable to its setter's parameter type. Setting `value` to `null` will throw an `Error`.
	 *
	 * When getting:
	 * - A return value of `null` means the previous value was overridden (e.g., {@link Color.multiply multiply},
	 *   {@link Color.premultiply premultiply} or {@link Color.round round}).
	 * - Otherwise, the color source used when setting is returned.
	 */
	set value(value: ColorSource | null);
	get value(): Exclude<ColorSource, Color> | null;
	/**
	 * Copy a color source internally.
	 * @param value - Color source
	 */
	private _cloneSource;
	/**
	 * Equality check for color sources.
	 * @param value1 - First color source
	 * @param value2 - Second color source
	 * @returns `true` if the color sources are equal, `false` otherwise.
	 */
	private _isSourceEqual;
	/**
	 * Convert to a RGBA color object.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toRgb(); // returns { r: 1, g: 1, b: 1, a: 1 }
	 */
	toRgba(): RgbaColor;
	/**
	 * Convert to a RGB color object.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toRgb(); // returns { r: 1, g: 1, b: 1 }
	 */
	toRgb(): RgbColor;
	/** Convert to a CSS-style rgba string: `rgba(255,255,255,1.0)`. */
	toRgbaString(): string;
	/**
	 * Convert to an [R, G, B] array of clamped uint8 values (0 to 255).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toUint8RgbArray(); // returns [255, 255, 255]
	 * @param {number[]|Uint8Array|Uint8ClampedArray} [out] - Output array
	 */
	toUint8RgbArray(): number[];
	toUint8RgbArray<T extends number[] | Uint8Array | Uint8ClampedArray>(out: T): T;
	/**
	 * Convert to an [R, G, B, A] array of normalized floats (numbers from 0.0 to 1.0).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toArray(); // returns [1, 1, 1, 1]
	 * @param {number[]|Float32Array} [out] - Output array
	 */
	toArray(): number[];
	toArray<T extends number[] | Float32Array>(out: T): T;
	/**
	 * Convert to an [R, G, B] array of normalized floats (numbers from 0.0 to 1.0).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toRgbArray(); // returns [1, 1, 1]
	 * @param {number[]|Float32Array} [out] - Output array
	 */
	toRgbArray(): number[];
	toRgbArray<T extends number[] | Float32Array>(out: T): T;
	/**
	 * Convert to a hexadecimal number.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toNumber(); // returns 16777215
	 */
	toNumber(): number;
	/**
	 * Convert to a BGR number
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color(0xffcc99).toBgrNumber(); // returns 0x99ccff
	 */
	toBgrNumber(): number;
	/**
	 * Convert to a hexadecimal number in little endian format (e.g., BBGGRR).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color(0xffcc99).toLittleEndianNumber(); // returns 0x99ccff
	 * @returns {number} - The color as a number in little endian format.
	 */
	toLittleEndianNumber(): number;
	/**
	 * Multiply with another color. This action is destructive, and will
	 * override the previous `value` property to be `null`.
	 * @param {ColorSource} value - The color to multiply by.
	 */
	multiply(value: ColorSource): this;
	/**
	 * Converts color to a premultiplied alpha format. This action is destructive, and will
	 * override the previous `value` property to be `null`.
	 * @param alpha - The alpha to multiply by.
	 * @param {boolean} [applyToRGB=true] - Whether to premultiply RGB channels.
	 * @returns {Color} - Itself.
	 */
	premultiply(alpha: number, applyToRGB?: boolean): this;
	/**
	 * Premultiplies alpha with current color.
	 * @param {number} alpha - The alpha to multiply by.
	 * @param {boolean} [applyToRGB=true] - Whether to premultiply RGB channels.
	 * @returns {number} tint multiplied by alpha
	 */
	toPremultiplied(alpha: number, applyToRGB?: boolean): number;
	/**
	 * Convert to a hexadecimal string.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toHex(); // returns "#ffffff"
	 */
	toHex(): string;
	/**
	 * Convert to a hexadecimal string with alpha.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toHexa(); // returns "#ffffffff"
	 */
	toHexa(): string;
	/**
	 * Set alpha, suitable for chaining.
	 * @param alpha
	 */
	setAlpha(alpha: number): this;
	/**
	 * Normalize the input value into rgba
	 * @param value - Input value
	 */
	private _normalize;
	/** Refresh the internal color rgb number */
	private _refreshInt;
	/**
	 * Clamps values to a range. Will override original values
	 * @param value - Value(s) to clamp
	 * @param min - Minimum value
	 * @param max - Maximum value
	 */
	private _clamp;
	/**
	 * Check if the value is a color-like object
	 * @param value - Value to check
	 * @returns True if the value is a color-like object
	 * @static
	 * @example
	 * import { Color } from 'pixi.js';
	 * Color.isColorLike('white'); // returns true
	 * Color.isColorLike(0xffffff); // returns true
	 * Color.isColorLike([1, 1, 1]); // returns true
	 */
	static isColorLike(value: unknown): value is ColorSource;
}
/**
 * Common interface for points. Both Point and ObservablePoint implement it
 * @memberof maths
 */
export interface PointData {
	/** X coord */
	x: number;
	/** Y coord */
	y: number;
}
/**
 * Common interface for points. Both Point and ObservablePoint implement it
 * @memberof maths
 */
export interface PointLike extends PointData {
	/**
	 * Copies x and y from the given point
	 * @param {PointData} p - The point to copy from
	 * @returns {this} Returns itself.
	 */
	copyFrom: (p: PointData) => this;
	/**
	 * Copies x and y into the given point
	 * @param {PointLike} p - The point to copy.
	 * @returns {PointLike} Given point with values updated
	 */
	copyTo: <T extends PointLike>(p: T) => T;
	/**
	 * Returns true if the given point is equal to this point
	 * @param {PointData} p - The point to check
	 * @returns {boolean} Whether the given point equal to this point
	 */
	equals: (p: PointData) => boolean;
	/**
	 * Sets the point to a new x and y position.
	 * If y is omitted, both x and y will be set to x.
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=x] - position of the point on the y axis
	 */
	set: (x?: number, y?: number) => void;
}
export interface Point extends PixiMixins.Point {
}
/**
 * The Point object represents a location in a two-dimensional coordinate system, where `x` represents
 * the position on the horizontal axis and `y` represents the position on the vertical axis.
 * <br/>
 * Many Pixi functions accept the `PointData` type as an alternative to `Point`,
 * which only requires `x` and `y` properties.
 * @class
 * @implements {PointLike}
 * @memberof maths
 */
export declare class Point implements PointLike {
	/** Position of the point on the x axis */
	x: number;
	/** Position of the point on the y axis */
	y: number;
	/**
	 * Creates a new `Point`
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=0] - position of the point on the y axis
	 */
	constructor(x?: number, y?: number);
	/**
	 * Creates a clone of this point
	 * @returns A clone of this point
	 */
	clone(): Point;
	/**
	 * Copies `x` and `y` from the given point into this point
	 * @param p - The point to copy from
	 * @returns The point instance itself
	 */
	copyFrom(p: PointData): this;
	/**
	 * Copies this point's x and y into the given point (`p`).
	 * @param p - The point to copy to. Can be any of type that is or extends `PointData`
	 * @returns The point (`p`) with values updated
	 */
	copyTo<T extends PointLike>(p: T): T;
	/**
	 * Accepts another point (`p`) and returns `true` if the given point is equal to this point
	 * @param p - The point to check
	 * @returns Returns `true` if both `x` and `y` are equal
	 */
	equals(p: PointData): boolean;
	/**
	 * Sets the point to a new `x` and `y` position.
	 * If `y` is omitted, both `x` and `y` will be set to `x`.
	 * @param {number} [x=0] - position of the point on the `x` axis
	 * @param {number} [y=x] - position of the point on the `y` axis
	 * @returns The point instance itself
	 */
	set(x?: number, y?: number): this;
	toString(): string;
	/**
	 * A static Point object with `x` and `y` values of `0`. Can be used to avoid creating new objects multiple times.
	 * @readonly
	 */
	static get shared(): Point;
}
interface TransformableObject {
	position: PointData;
	scale: PointData;
	pivot: PointData;
	skew: PointData;
	rotation: number;
}
/**
 * A fast matrix for 2D transformations.
 * ```js
 * | a | c | tx|
 * | b | d | ty|
 * | 0 | 0 | 1 |
 * ```
 * @memberof maths
 */
export declare class Matrix {
	/** @default 1 */
	a: number;
	/** @default 0 */
	b: number;
	/** @default 0 */
	c: number;
	/** @default 1 */
	d: number;
	/** @default 0 */
	tx: number;
	/** @default 0 */
	ty: number;
	/** An array of the current matrix. Only populated when `toArray` is called */
	array: Float32Array | null;
	/**
	 * @param a - x scale
	 * @param b - y skew
	 * @param c - x skew
	 * @param d - y scale
	 * @param tx - x translation
	 * @param ty - y translation
	 */
	constructor(a?: number, b?: number, c?: number, d?: number, tx?: number, ty?: number);
	/**
	 * Creates a Matrix object based on the given array. The Element to Matrix mapping order is as follows:
	 *
	 * a = array[0]
	 * b = array[1]
	 * c = array[3]
	 * d = array[4]
	 * tx = array[2]
	 * ty = array[5]
	 * @param array - The array that the matrix will be populated from.
	 */
	fromArray(array: number[]): void;
	/**
	 * Sets the matrix properties.
	 * @param a - Matrix component
	 * @param b - Matrix component
	 * @param c - Matrix component
	 * @param d - Matrix component
	 * @param tx - Matrix component
	 * @param ty - Matrix component
	 * @returns This matrix. Good for chaining method calls.
	 */
	set(a: number, b: number, c: number, d: number, tx: number, ty: number): this;
	/**
	 * Creates an array from the current Matrix object.
	 * @param transpose - Whether we need to transpose the matrix or not
	 * @param [out=new Float32Array(9)] - If provided the array will be assigned to out
	 * @returns The newly created array which contains the matrix
	 */
	toArray(transpose?: boolean, out?: Float32Array): Float32Array;
	/**
	 * Get a new position with the current transformation applied.
	 * Can be used to go from a child's coordinate space to the world coordinate space. (e.g. rendering)
	 * @param pos - The origin
	 * @param {Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
	 * @returns {Point} The new point, transformed through this matrix
	 */
	apply<P extends PointData = Point>(pos: PointData, newPos?: P): P;
	/**
	 * Get a new position with the inverse of the current transformation applied.
	 * Can be used to go from the world coordinate space to a child's coordinate space. (e.g. input)
	 * @param pos - The origin
	 * @param {Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
	 * @returns {Point} The new point, inverse-transformed through this matrix
	 */
	applyInverse<P extends PointData = Point>(pos: PointData, newPos?: P): P;
	/**
	 * Translates the matrix on the x and y.
	 * @param x - How much to translate x by
	 * @param y - How much to translate y by
	 * @returns This matrix. Good for chaining method calls.
	 */
	translate(x: number, y: number): this;
	/**
	 * Applies a scale transformation to the matrix.
	 * @param x - The amount to scale horizontally
	 * @param y - The amount to scale vertically
	 * @returns This matrix. Good for chaining method calls.
	 */
	scale(x: number, y: number): this;
	/**
	 * Applies a rotation transformation to the matrix.
	 * @param angle - The angle in radians.
	 * @returns This matrix. Good for chaining method calls.
	 */
	rotate(angle: number): this;
	/**
	 * Appends the given Matrix to this Matrix.
	 * @param matrix - The matrix to append.
	 * @returns This matrix. Good for chaining method calls.
	 */
	append(matrix: Matrix): this;
	/**
	 * Appends two matrix's and sets the result to this matrix. AB = A * B
	 * @param a - The matrix to append.
	 * @param b - The matrix to append.
	 * @returns This matrix. Good for chaining method calls.
	 */
	appendFrom(a: Matrix, b: Matrix): this;
	/**
	 * Sets the matrix based on all the available properties
	 * @param x - Position on the x axis
	 * @param y - Position on the y axis
	 * @param pivotX - Pivot on the x axis
	 * @param pivotY - Pivot on the y axis
	 * @param scaleX - Scale on the x axis
	 * @param scaleY - Scale on the y axis
	 * @param rotation - Rotation in radians
	 * @param skewX - Skew on the x axis
	 * @param skewY - Skew on the y axis
	 * @returns This matrix. Good for chaining method calls.
	 */
	setTransform(x: number, y: number, pivotX: number, pivotY: number, scaleX: number, scaleY: number, rotation: number, skewX: number, skewY: number): this;
	/**
	 * Prepends the given Matrix to this Matrix.
	 * @param matrix - The matrix to prepend
	 * @returns This matrix. Good for chaining method calls.
	 */
	prepend(matrix: Matrix): this;
	/**
	 * Decomposes the matrix (x, y, scaleX, scaleY, and rotation) and sets the properties on to a transform.
	 * @param transform - The transform to apply the properties to.
	 * @returns The transform with the newly applied properties
	 */
	decompose(transform: TransformableObject): TransformableObject;
	/**
	 * Inverts this matrix
	 * @returns This matrix. Good for chaining method calls.
	 */
	invert(): this;
	/** Checks if this matrix is an identity matrix */
	isIdentity(): boolean;
	/**
	 * Resets this Matrix to an identity (default) matrix.
	 * @returns This matrix. Good for chaining method calls.
	 */
	identity(): this;
	/**
	 * Creates a new Matrix object with the same values as this one.
	 * @returns A copy of this matrix. Good for chaining method calls.
	 */
	clone(): Matrix;
	/**
	 * Changes the values of the given matrix to be the same as the ones in this matrix
	 * @param matrix - The matrix to copy to.
	 * @returns The matrix given in parameter with its values updated.
	 */
	copyTo(matrix: Matrix): Matrix;
	/**
	 * Changes the values of the matrix to be the same as the ones in given matrix
	 * @param matrix - The matrix to copy from.
	 * @returns this
	 */
	copyFrom(matrix: Matrix): this;
	/**
	 * check to see if two matrices are the same
	 * @param matrix - The matrix to compare to.
	 */
	equals(matrix: Matrix): boolean;
	toString(): string;
	/**
	 * A default (identity) matrix.
	 *
	 * This is a shared object, if you want to modify it consider creating a new `Matrix`
	 * @readonly
	 */
	static get IDENTITY(): Readonly<Matrix>;
	/**
	 * A static Matrix that can be used to avoid creating new objects.
	 * Will always ensure the matrix is reset to identity when requested.
	 * Use this object for fast but temporary calculations, as it may be mutated later on.
	 * This is a different object to the `IDENTITY` object and so can be modified without changing `IDENTITY`.
	 * @readonly
	 */
	static get shared(): Matrix;
}
export interface ObservablePoint extends PixiMixins.ObservablePoint {
}
/**
 * Observer used to listen for observable point changes.
 * @memberof maths
 */
export interface Observer<T> {
	/** Callback to call when the point has updated. */
	_onUpdate: (point?: T) => void;
}
/**
 * The ObservablePoint object represents a location in a two-dimensional coordinate system, where `x` represents
 * the position on the horizontal axis and `y` represents the position on the vertical axis.
 *
 * An `ObservablePoint` is a point that triggers the `onUpdate` method on an observer when the point's position is changed.
 * @memberof maths
 */
export declare class ObservablePoint implements PointLike {
	/** @ignore */
	_x: number;
	/** @ignore */
	_y: number;
	/** This object used to call the `onUpdate` callback when the point changes. */
	private readonly _observer;
	/**
	 * Creates a new `ObservablePoint`
	 * @param observer - Observer to pass to listen for change events.
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=0] - position of the point on the y axis
	 */
	constructor(observer: Observer<ObservablePoint>, x?: number, y?: number);
	/**
	 * Creates a clone of this point.
	 * @param observer - Optional observer to pass to the new observable point.
	 * @returns a copy of this observable point
	 */
	clone(observer?: Observer<ObservablePoint>): ObservablePoint;
	/**
	 * Sets the point to a new `x` and `y` position.
	 * If `y` is omitted, both `x` and `y` will be set to `x`.
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=x] - position of the point on the y axis
	 * @returns The observable point instance itself
	 */
	set(x?: number, y?: number): this;
	/**
	 * Copies x and y from the given point (`p`)
	 * @param p - The point to copy from. Can be any of type that is or extends `PointData`
	 * @returns The observable point instance itself
	 */
	copyFrom(p: PointData): this;
	/**
	 * Copies this point's x and y into that of the given point (`p`)
	 * @param p - The point to copy to. Can be any of type that is or extends `PointData`
	 * @returns The point (`p`) with values updated
	 */
	copyTo<T extends PointLike>(p: T): T;
	/**
	 * Accepts another point (`p`) and returns `true` if the given point is equal to this point
	 * @param p - The point to check
	 * @returns Returns `true` if both `x` and `y` are equal
	 */
	equals(p: PointData): boolean;
	toString(): string;
	/** Position of the observable point on the x axis. */
	get x(): number;
	set x(value: number);
	/** Position of the observable point on the y axis. */
	get y(): number;
	set y(value: number);
}
/**
 * Two Pi.
 * @static
 * @member {number}
 * @memberof maths
 */
export declare const PI_2: number;
/**
 * Conversion factor for converting radians to degrees.
 * @static
 * @member {number} RAD_TO_DEG
 * @memberof maths
 */
export declare const RAD_TO_DEG: number;
/**
 * Conversion factor for converting degrees to radians.
 * @static
 * @member {number}
 * @memberof maths
 */
export declare const DEG_TO_RAD: number;
/**
 * Constants that identify shapes, mainly to prevent `instanceof` calls.
 * @memberof maths
 */
export type SHAPE_PRIMITIVE = "polygon" | "rectangle" | "circle" | "ellipse" | "triangle" | "roundedRectangle";
/**
 * A basic object to define a Pixi shape.
 * @memberof maths
 */
export interface ShapePrimitive {
	/** The type of the object, mainly used to avoid `instanceof` checks */
	readonly type: SHAPE_PRIMITIVE;
	/** Checks whether the x and y coordinates passed to this function are contained within this ShapePrimitive. */
	contains(x: number, y: number): boolean;
	/** Checks whether the x and y coordinates passed to this function are contained within the stroke of this shape */
	strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
	/** Creates a clone of this ShapePrimitive instance. */
	clone(): ShapePrimitive;
	/** Copies the properties from another ShapePrimitive to this ShapePrimitive. */
	copyFrom(source: ShapePrimitive): void;
	/** Copies the properties from this ShapePrimitive to another ShapePrimitive. */
	copyTo(destination: ShapePrimitive): void;
	/** Returns the framing rectangle of the ShapePrimitive as a Rectangle object. */
	getBounds(out?: Rectangle): Rectangle;
	/** The X coordinate of the shape */
	readonly x: number;
	/** The Y coordinate of the shape */
	readonly y: number;
}
export interface Rectangle extends PixiMixins.Rectangle {
}
/**
 * The `Rectangle` object is an area defined by its position, as indicated by its top-left corner
 * point (`x`, `y`) and by its `width` and its `height`.
 *
 * It also provides convenience methods to get and set the position and size of the rectangle such as
 * {@link maths.Rectangle#bottom|bottom}, {@link maths.Rectangle#right|right} and {@link maths.Rectangle#isEmpty|isEmpty}.
 * @memberof maths
 */
export declare class Rectangle implements ShapePrimitive {
	/**
	 * The type of the object, mainly used to avoid `instanceof` checks
	 * @default 'rectangle'
	 */
	readonly type: SHAPE_PRIMITIVE;
	/**
	 * The X coordinate of the upper-left corner of the rectangle
	 * @default 0
	 */
	x: number;
	/**
	 * The Y coordinate of the upper-left corner of the rectangle
	 * @default 0
	 */
	y: number;
	/**
	 * The overall width of this rectangle
	 *  @default 0
	 */
	width: number;
	/**
	 * The overall height of this rectangle
	 * @default 0
	 */
	height: number;
	/**
	 * @param x - The X coordinate of the upper-left corner of the rectangle
	 * @param y - The Y coordinate of the upper-left corner of the rectangle
	 * @param width - The overall width of the rectangle
	 * @param height - The overall height of the rectangle
	 */
	constructor(x?: string | number, y?: string | number, width?: string | number, height?: string | number);
	/** Returns the left edge of the rectangle. */
	get left(): number;
	/** Returns the right edge of the rectangle. */
	get right(): number;
	/** Returns the top edge of the rectangle. */
	get top(): number;
	/** Returns the bottom edge of the rectangle. */
	get bottom(): number;
	/** Determines whether the Rectangle is empty. */
	isEmpty(): boolean;
	/** A constant empty rectangle. This is a new object every time the property is accessed */
	static get EMPTY(): Rectangle;
	/**
	 * Creates a clone of this Rectangle
	 * @returns a copy of the rectangle
	 */
	clone(): Rectangle;
	/**
	 * Converts a Bounds object to a Rectangle object.
	 * @param bounds - The bounds to copy and convert to a rectangle.
	 * @returns Returns itself.
	 */
	copyFromBounds(bounds: Bounds): this;
	/**
	 * Copies another rectangle to this one.
	 * @param rectangle - The rectangle to copy from.
	 * @returns Returns itself.
	 */
	copyFrom(rectangle: Rectangle): Rectangle;
	/**
	 * Copies this rectangle to another one.
	 * @param rectangle - The rectangle to copy to.
	 * @returns Returns given parameter.
	 */
	copyTo(rectangle: Rectangle): Rectangle;
	/**
	 * Checks whether the x and y coordinates given are contained within this Rectangle
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @returns Whether the x/y coordinates are within this Rectangle
	 */
	contains(x: number, y: number): boolean;
	/**
	 * Checks whether the x and y coordinates given are contained within this rectangle including the stroke.
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @param strokeWidth - The width of the line to check
	 * @param alignment - The alignment of the stroke, 0.5 by default
	 * @returns Whether the x/y coordinates are within this rectangle
	 */
	strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
	/**
	 * Determines whether the `other` Rectangle transformed by `transform` intersects with `this` Rectangle object.
	 * Returns true only if the area of the intersection is >0, this means that Rectangles
	 * sharing a side are not overlapping. Another side effect is that an arealess rectangle
	 * (width or height equal to zero) can't intersect any other rectangle.
	 * @param {Rectangle} other - The Rectangle to intersect with `this`.
	 * @param {Matrix} transform - The transformation matrix of `other`.
	 * @returns {boolean} A value of `true` if the transformed `other` Rectangle intersects with `this`; otherwise `false`.
	 */
	intersects(other: Rectangle, transform?: Matrix): boolean;
	/**
	 * Pads the rectangle making it grow in all directions.
	 * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
	 * @param paddingX - The horizontal padding amount.
	 * @param paddingY - The vertical padding amount.
	 * @returns Returns itself.
	 */
	pad(paddingX?: number, paddingY?: number): this;
	/**
	 * Fits this rectangle around the passed one.
	 * @param rectangle - The rectangle to fit.
	 * @returns Returns itself.
	 */
	fit(rectangle: Rectangle): this;
	/**
	 * Enlarges rectangle that way its corners lie on grid
	 * @param resolution - resolution
	 * @param eps - precision
	 * @returns Returns itself.
	 */
	ceil(resolution?: number, eps?: number): this;
	/**
	 * Enlarges this rectangle to include the passed rectangle.
	 * @param rectangle - The rectangle to include.
	 * @returns Returns itself.
	 */
	enlarge(rectangle: Rectangle): this;
	/**
	 * Returns the framing rectangle of the rectangle as a Rectangle object
	 * @param out - optional rectangle to store the result
	 * @returns The framing rectangle
	 */
	getBounds(out?: Rectangle): Rectangle;
	toString(): string;
}
/**
 * Simple bounds implementation instead of more ambiguous [number, number, number, number]
 * @memberof rendering
 */
export interface BoundsData {
	minX: number;
	minY: number;
	maxX: number;
	maxY: number;
}
/**
 * A representation of an AABB bounding box.
 * @memberof rendering
 */
export declare class Bounds {
	/** @default Infinity */
	minX: number;
	/** @default Infinity */
	minY: number;
	/** @default -Infinity */
	maxX: number;
	/** @default -Infinity */
	maxY: number;
	matrix: Matrix;
	private _rectangle;
	constructor(minX?: number, minY?: number, maxX?: number, maxY?: number);
	/**
	 * Checks if bounds are empty.
	 * @returns - True if empty.
	 */
	isEmpty(): boolean;
	/** The bounding rectangle of the bounds. */
	get rectangle(): Rectangle;
	/** Clears the bounds and resets. */
	clear(): this;
	/**
	 * Sets the bounds.
	 * @param x0 - left X of frame
	 * @param y0 - top Y of frame
	 * @param x1 - right X of frame
	 * @param y1 - bottom Y of frame
	 */
	set(x0: number, y0: number, x1: number, y1: number): void;
	/**
	 * Adds sprite frame
	 * @param x0 - left X of frame
	 * @param y0 - top Y of frame
	 * @param x1 - right X of frame
	 * @param y1 - bottom Y of frame
	 * @param matrix
	 */
	addFrame(x0: number, y0: number, x1: number, y1: number, matrix?: Matrix): void;
	/**
	 * Adds a rectangle to the bounds.
	 * @param rect - The rectangle to be added.
	 * @param matrix - The matrix to apply to the bounds.
	 */
	addRect(rect: Rectangle, matrix?: Matrix): void;
	/**
	 * Adds other {@link Bounds}.
	 * @param bounds - The Bounds to be added
	 * @param matrix
	 */
	addBounds(bounds: BoundsData, matrix?: Matrix): void;
	/**
	 * Adds other Bounds, masked with Bounds.
	 * @param mask - The Bounds to be added.
	 */
	addBoundsMask(mask: Bounds): void;
	/**
	 * Adds other Bounds, multiplied with matrix.
	 * @param matrix - The matrix to apply to the bounds.
	 */
	applyMatrix(matrix: Matrix): void;
	/**
	 * Resizes the bounds object to include the given rectangle.
	 * @param rect - The rectangle to be included.
	 */
	fit(rect: Rectangle): this;
	/**
	 * Resizes the bounds object to include the given bounds.
	 * @param left - The left value of the bounds.
	 * @param right - The right value of the bounds.
	 * @param top - The top value of the bounds.
	 * @param bottom - The bottom value of the bounds.
	 */
	fitBounds(left: number, right: number, top: number, bottom: number): this;
	/**
	 * Pads bounds object, making it grow in all directions.
	 * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
	 * @param paddingX - The horizontal padding amount.
	 * @param paddingY - The vertical padding amount.
	 */
	pad(paddingX: number, paddingY?: number): this;
	/** Ceils the bounds. */
	ceil(): this;
	/** Clones the bounds. */
	clone(): Bounds;
	/**
	 * Scales the bounds by the given values
	 * @param x - The X value to scale by.
	 * @param y - The Y value to scale by.
	 */
	scale(x: number, y?: number): this;
	/** the x value of the bounds. */
	get x(): number;
	set x(value: number);
	/** the y value of the bounds. */
	get y(): number;
	set y(value: number);
	/** the width value of the bounds. */
	get width(): number;
	set width(value: number);
	/** the height value of the bounds. */
	get height(): number;
	set height(value: number);
	/** the left value of the bounds. */
	get left(): number;
	/** the right value of the bounds. */
	get right(): number;
	/** the top value of the bounds. */
	get top(): number;
	/** the bottom value of the bounds. */
	get bottom(): number;
	/** Is the bounds positive. */
	get isPositive(): boolean;
	get isValid(): boolean;
	/**
	 * Adds screen vertices from array
	 * @param vertexData - calculated vertices
	 * @param beginOffset - begin offset
	 * @param endOffset - end offset, excluded
	 * @param matrix
	 */
	addVertexData(vertexData: Float32Array, beginOffset: number, endOffset: number, matrix?: Matrix): void;
	/**
	 * Checks if the point is contained within the bounds.
	 * @param x - x coordinate
	 * @param y - y coordinate
	 */
	containsPoint(x: number, y: number): boolean;
	toString(): string;
	/**
	 * Copies the bounds from another bounds object.
	 * @param bounds - The bounds to copy from.
	 * @returns - This bounds object.
	 */
	copyFrom(bounds: Bounds): this;
}
export interface ViewObserver {
	onViewUpdate: () => void;
}
/**
 * A view is something that is able to be rendered by the renderer.
 * @memberof scene
 */
export interface View {
	/** a unique id for this view */
	readonly uid: number;
	/** whether or not this view should be batched */
	batched: boolean;
	/**
	 * an identifier that is used to identify the type of system that will be used to render this renderable
	 * eg, 'sprite' will use the sprite system (based on the systems name
	 */
	readonly renderPipeId: string;
	/** this is an int because it is packed directly into an attribute in the shader */
	_roundPixels: 0 | 1;
	/** @private */
	_lastUsed: number;
	/**
	 *  Whether or not to round the x/y position of the object.
	 * @type {boolean}
	 */
	get roundPixels(): boolean;
	/** if true, the view will have its position rounded to the nearest whole number */
	set roundPixels(value: boolean);
	/** this is the AABB rectangle bounds of the view in local untransformed space. */
	bounds: BoundsData;
	/** Checks if the point is within the view */
	containsPoint: (point: Point) => boolean;
}
export interface Renderable extends Container, View {
}
/**
 * An instruction that can be executed by the renderer
 * @memberof rendering
 */
export interface Instruction {
	/** a the id of the render pipe that can run this instruction */
	renderPipeId: string;
	/** the name of the instruction */
	action?: string;
	/** true if this instruction can be compiled into a WebGPU bundle */
	canBundle: boolean;
}
/**
 * A set of instructions that can be executed by the renderer.
 * Basically wraps an array, but with some extra properties that help the renderer
 * to keep things nice and optimised.
 *
 * Note:
 * InstructionSet.instructions contains all the instructions, but does not resize (for performance).
 * So for the true length of the instructions you need to use InstructionSet.instructionSize
 * @memberof rendering
 */
export declare class InstructionSet {
	/** a unique id for this instruction set used through the renderer */
	readonly uid: number;
	/** the array of instructions */
	readonly instructions: Instruction[];
	/** the actual size of the array (any instructions passed this should be ignored) */
	instructionSize: number;
	/** allows for access to the render pipes of the renderer */
	renderPipes: any;
	renderables: Renderable[];
	/** used by the garbage collector to track when the instruction set was last used */
	gcTick: number;
	/** reset the instruction set so it can be reused set size back to 0 */
	reset(): void;
	/**
	 * Add an instruction to the set
	 * @param instruction - add an instruction to the set
	 */
	add(instruction: Instruction): void;
	/**
	 * Log the instructions to the console (for debugging)
	 * @internal
	 * @ignore
	 */
	log(): void;
}
/**
 * A bind group is a collection of resources that are bound together for use by a shader.
 * They are essentially a wrapper for the WebGPU BindGroup class. But with the added bonus
 * that WebGL can also work with them.
 * @see https://gpuweb.github.io/gpuweb/#dictdef-gpubindgroupdescriptor
 * @example
 * // Create a bind group with a single texture and sampler
 * const bindGroup = new BindGroup({
 *    uTexture: texture.source,
 *    uTexture: texture.style,
 * });
 *
 * Bind groups resources must implement the {@link BindResource} interface.
 * The following resources are supported:
 * - {@link TextureSource}
 * - {@link TextureStyle}
 * - {@link Buffer}
 * - {@link BufferResource}
 * - {@link UniformGroup}
 *
 * The keys in the bind group must correspond to the names of the resources in the GPU program.
 *
 * This bind group class will also watch for changes in its resources ensuring that the changes
 * are reflected in the WebGPU BindGroup.
 * @memberof rendering
 */
export declare class BindGroup {
	/** The resources that are bound together for use by a shader. */
	resources: Record<string, BindResource>;
	/**
	 * a key used internally to match it up to a WebGPU Bindgroup
	 * @internal
	 * @ignore
	 */
	_key: string;
	private _dirty;
	/**
	 * Create a new instance eof the Bind Group.
	 * @param resources - The resources that are bound together for use by a shader.
	 */
	constructor(resources?: Record<string, BindResource>);
	/**
	 * Updates the key if its flagged as dirty. This is used internally to
	 * match this bind group to a WebGPU BindGroup.
	 * @internal
	 * @ignore
	 */
	_updateKey(): void;
	/**
	 * Set a resource at a given index. this function will
	 * ensure that listeners will be removed from the current resource
	 * and added to the new resource.
	 * @param resource - The resource to set.
	 * @param index - The index to set the resource at.
	 */
	setResource(resource: BindResource, index: number): void;
	/**
	 * Returns the resource at the current specified index.
	 * @param index - The index of the resource to get.
	 * @returns - The resource at the specified index.
	 */
	getResource(index: number): BindResource;
	/**
	 * Used internally to 'touch' each resource, to ensure that the GC
	 * knows that all resources in this bind group are still being used.
	 * @param tick - The current tick.
	 * @internal
	 * @ignore
	 */
	_touch(tick: number): void;
	/** Destroys this bind group and removes all listeners. */
	destroy(): void;
	protected onResourceChange(resource: BindResource): void;
}
/**
 * an interface that allows a resource to be bound to the gpu in a bind group
 * @memberof rendering
 */
export interface BindResource {
	/**
	 * The type of resource this is
	 * @ignore
	 */
	_resourceType: string;
	/**
	 * Unique id for this resource this can change and is used to link the gpu
	 * @ignore
	 */
	_resourceId: number;
	_touched: number;
	/**
	 * a boolean that indicates if the resource has been destroyed.
	 * If true, the resource should not be used and any bind groups
	 * that will release any references to this resource.
	 * @ignore
	 */
	destroyed: boolean;
	/**
	 * event dispatch whenever the underlying resource needs to change
	 * this could be a texture or buffer that has been resized.
	 * This is important as it allows the renderer to know that it needs to rebind the resource
	 */
	on?(event: "change", listenerFunction: (resource: BindResource) => void, listener: BindGroup): void;
	/** @todo */
	off?(event: "change", listenerFunction: (resource: BindResource) => void, listener: BindGroup): void;
}
/**
 * Specifies the alpha composition mode for textures.
 *
 * - `no-premultiply-alpha`: Does not premultiply alpha.
 * - `premultiply-alpha-on-upload`: Premultiplies alpha on texture upload.
 * - `premultiplied-alpha`: Assumes the texture is already in premultiplied alpha format.
 * @typedef {'no-premultiply-alpha' | 'premultiply-alpha-on-upload' | 'premultiplied-alpha'} ALPHA_MODES
 */
export type ALPHA_MODES = "no-premultiply-alpha" | "premultiply-alpha-on-upload" | "premultiplied-alpha";
/**
 * Constants for multi-sampling antialiasing.
 * @see Framebuffer#multisample
 * @name MSAA_QUALITY
 * @static
 * @enum {number}
 * @property {number} NONE - No multisampling for this renderTexture
 * @property {number} LOW - Try 2 samples
 * @property {number} MEDIUM - Try 4 samples
 * @property {number} HIGH - Try 8 samples
 */
export declare enum MSAA_QUALITY {
	NONE = 0,
	LOW = 2,
	MEDIUM = 4,
	HIGH = 8
}
export type TEXTURE_FORMATS = "r8unorm" | "r8snorm" | "r8uint" | "r8sint" | "r16uint" | "r16sint" | "r16float" | "rg8unorm" | "rg8snorm" | "rg8uint" | "rg8sint" | "r32uint" | "r32sint" | "r32float" | "rg16uint" | "rg16sint" | "rg16float" | "rgba8unorm" | "rgba8unorm-srgb" | "rgba8snorm" | "rgba8uint" | "rgba8sint" | "bgra8unorm" | "bgra8unorm-srgb" | "rgb9e5ufloat" | "rgb10a2unorm" | "rg11b10ufloat" | "rg32uint" | "rg32sint" | "rg32float" | "rgba16uint" | "rgba16sint" | "rgba16float" | "rgba32uint" | "rgba32sint" | "rgba32float" | "stencil8" | "depth16unorm" | "depth24plus" | "depth24plus-stencil8" | "depth32float" | "depth32float-stencil8" | "bc1-rgba-unorm" | "bc1-rgba-unorm-srgb" | "bc2-rgba-unorm" | "bc2-rgba-unorm-srgb" | "bc3-rgba-unorm" | "bc3-rgba-unorm-srgb" | "bc4-r-unorm" | "bc4-r-snorm" | "bc5-rg-unorm" | "bc5-rg-snorm" | "bc6h-rgb-ufloat" | "bc6h-rgb-float" | "bc7-rgba-unorm" | "bc7-rgba-unorm-srgb" | "etc2-rgb8unorm" | "etc2-rgb8unorm-srgb" | "etc2-rgb8a1unorm" | "etc2-rgb8a1unorm-srgb" | "etc2-rgba8unorm" | "etc2-rgba8unorm-srgb" | "eac-r11unorm" | "eac-r11snorm" | "eac-rg11unorm" | "eac-rg11snorm" | "astc-4x4-unorm" | "astc-4x4-unorm-srgb" | "astc-5x4-unorm" | "astc-5x4-unorm-srgb" | "astc-5x5-unorm" | "astc-5x5-unorm-srgb" | "astc-6x5-unorm" | "astc-6x5-unorm-srgb" | "astc-6x6-unorm" | "astc-6x6-unorm-srgb" | "astc-8x5-unorm" | "astc-8x5-unorm-srgb" | "astc-8x6-unorm" | "astc-8x6-unorm-srgb" | "astc-8x8-unorm" | "astc-8x8-unorm-srgb" | "astc-10x5-unorm" | "astc-10x5-unorm-srgb" | "astc-10x6-unorm" | "astc-10x6-unorm-srgb" | "astc-10x8-unorm" | "astc-10x8-unorm-srgb" | "astc-10x10-unorm" | "astc-10x10-unorm-srgb" | "astc-12x10-unorm" | "astc-12x10-unorm-srgb" | "astc-12x12-unorm" | "astc-12x12-unorm-srgb";
export type TEXTURE_VIEW_DIMENSIONS = "1d" | "2d" | "2d-array" | "cube" | "cube-array" | "3d";
export type TEXTURE_DIMENSIONS = "1d" | "2d" | "3d";
export type WRAP_MODE = 
/**
 * The texture uvs are clamped
 * @default 33071
 */
"clamp-to-edge"
/**
 * The texture uvs tile and repeat
 * @default 10497
 */
 | "repeat"
/**
 * The texture uvs tile and repeat with mirroring
 * @default 33648
 */
 | "mirror-repeat";
export declare enum DEPRECATED_WRAP_MODES {
	CLAMP = "clamp-to-edge",
	REPEAT = "repeat",
	MIRRORED_REPEAT = "mirror-repeat"
}
/** @deprecated since 8.0.0 */
export declare const WRAP_MODES: typeof DEPRECATED_WRAP_MODES;
/**
 * The scale modes that are supported by pixi.
 *
 * The {@link settings.SCALE_MODE} scale mode affects the default scaling mode of future operations.
 * It can be re-assigned to either LINEAR or NEAREST, depending upon suitability.
 * @static
 */
export type SCALE_MODE = 
/** Pixelating scaling */
"nearest"
/** Smooth scaling */
 | "linear";
export declare enum DEPRECATED_SCALE_MODES {
	NEAREST = "nearest",
	LINEAR = "linear"
}
/**
 * @deprecated since 8.0.0
 */
export declare const SCALE_MODES: typeof DEPRECATED_SCALE_MODES;
export type COMPARE_FUNCTION = "never" | "less" | "equal" | "less-equal" | "greater" | "not-equal" | "greater-equal" | "always";
export interface TextureStyleOptions extends Partial<TextureStyle> {
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	addressMode?: WRAP_MODE;
	/** specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeU?: WRAP_MODE;
	/** specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeV?: WRAP_MODE;
	/** Specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeW?: WRAP_MODE;
	/** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
	scaleMode?: SCALE_MODE;
	/** specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
	magFilter?: SCALE_MODE;
	/** specifies the sampling behavior when the sample footprint is larger than one texel. */
	minFilter?: SCALE_MODE;
	/** specifies behavior for sampling between mipmap levels. */
	mipmapFilter?: SCALE_MODE;
	/** specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	lodMinClamp?: number;
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	lodMaxClamp?: number;
	/**
	 * When provided the sampler will be a comparison sampler with the specified
	 * {@link GPUCompareFunction}.
	 * Note: Comparison samplers may use filtering, but the sampling results will be
	 * implementation-dependent and may differ from the normal filtering rules.
	 */
	compare?: COMPARE_FUNCTION;
	/**
	 * Specifies the maximum anisotropy value clamp used by the sampler.
	 * Note: Most implementations support {@link GPUSamplerDescriptor#maxAnisotropy} values in range
	 * between 1 and 16, inclusive. The used value of {@link GPUSamplerDescriptor#maxAnisotropy} will
	 * be clamped to the maximum value that the platform supports.
	 *
	 * setting this to anything higher than 1 will set scale modes to 'linear'
	 */
	maxAnisotropy?: number;
}
/**
 * A texture style describes how a texture should be sampled by a shader.
 * @memberof rendering
 */
export declare class TextureStyle extends EventEmitter<{
	change: TextureStyle;
	destroy: TextureStyle;
}> implements BindResource {
	_resourceType: string;
	_touched: number;
	private _sharedResourceId;
	/** default options for the style */
	static readonly defaultOptions: TextureStyleOptions;
	/** */
	addressModeU?: WRAP_MODE;
	/** */
	addressModeV?: WRAP_MODE;
	/** Specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeW?: WRAP_MODE;
	/** Specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
	magFilter?: SCALE_MODE;
	/** Specifies the sampling behavior when the sample footprint is larger than one texel. */
	minFilter?: SCALE_MODE;
	/** Specifies behavior for sampling between mipmap levels. */
	mipmapFilter?: SCALE_MODE;
	/** */
	lodMinClamp?: number;
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	lodMaxClamp?: number;
	/**
	 * When provided the sampler will be a comparison sampler with the specified
	 * {@link GPUCompareFunction}.
	 * Note: Comparison samplers may use filtering, but the sampling results will be
	 * implementation-dependent and may differ from the normal filtering rules.
	 */
	compare?: COMPARE_FUNCTION;
	/**
	 * Specifies the maximum anisotropy value clamp used by the sampler.
	 * Note: Most implementations support {@link GPUSamplerDescriptor#maxAnisotropy} values in range
	 * between 1 and 16, inclusive. The used value of {@link GPUSamplerDescriptor#maxAnisotropy} will
	 * be clamped to the maximum value that the platform supports.
	 * @internal
	 * @ignore
	 */
	_maxAnisotropy?: number;
	/**
	 * Has the style been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	/**
	 * @param options - options for the style
	 */
	constructor(options?: TextureStyleOptions);
	set addressMode(value: WRAP_MODE);
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	get addressMode(): WRAP_MODE;
	set wrapMode(value: WRAP_MODE);
	get wrapMode(): WRAP_MODE;
	set scaleMode(value: SCALE_MODE);
	/** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
	get scaleMode(): SCALE_MODE;
	/** Specifies the maximum anisotropy value clamp used by the sampler. */
	set maxAnisotropy(value: number);
	get maxAnisotropy(): number;
	get _resourceId(): number;
	update(): void;
	private _generateResourceId;
	/** Destroys the style */
	destroy(): void;
}
/**
 * Common interface for CanvasRenderingContext2D, OffscreenCanvasRenderingContext2D, and other custom canvas 2D context.
 * @memberof environment
 */
export interface ICanvasRenderingContext2D extends CanvasState, CanvasTransform, CanvasCompositing, CanvasImageSmoothing, CanvasFillStrokeStyles, CanvasShadowStyles, CanvasFilters, CanvasRect, CanvasDrawPath, CanvasText, CanvasDrawImage, CanvasImageData, CanvasPathDrawingStyles, Omit<CanvasTextDrawingStyles, "letterSpacing">, CanvasPath {
	/** creates a pattern using the specified image and repetition. */
	createPattern(image: CanvasImageSource | ICanvas, repetition: string | null): CanvasPattern | null;
	/** provides different ways to draw an image onto the canvas */
	drawImage(image: CanvasImageSource | ICanvas, dx: number, dy: number): void;
	drawImage(image: CanvasImageSource | ICanvas, dx: number, dy: number, dw: number, dh: number): void;
	drawImage(image: CanvasImageSource | ICanvas, sx: number, sy: number, sw: number, sh: number, dx: number, dy: number, dw: number, dh: number): void;
	/** sets the horizontal spacing behavior between text characters. */
	letterSpacing?: string;
	/** sets the horizontal spacing behavior between text characters. */
	textLetterSpacing?: string;
}
export type ContextIds = "2d" | "bitmaprenderer" | "webgl" | "experimental-webgl" | "webgl2" | "experimental-webgl2" | "webgpu";
type PredefinedColorSpace$1 = "srgb" | "display-p3";
type RenderingContext$1 = ICanvasRenderingContext2D | ImageBitmapRenderingContext | WebGLRenderingContext | WebGL2RenderingContext;
export interface ICanvasRenderingContext2DSettings {
	alpha?: boolean;
	colorSpace?: PredefinedColorSpace$1;
	desynchronized?: boolean;
	willReadFrequently?: boolean;
}
export type ContextSettings = ICanvasRenderingContext2DSettings | ImageBitmapRenderingContextSettings | WebGLContextAttributes;
export interface ICanvasParentNode {
	/** Adds a node to the end of the list of children of the parent node. */
	appendChild(element: HTMLElement): void;
	/** Removes a child node from the parent node. */
	removeChild(element: HTMLElement): void;
	removeChild(element: ICanvas): void;
}
export interface ICanvasStyle {
	width?: string;
	height?: string;
	cursor?: string;
	touchAction?: string;
	msTouchAction?: string;
	msContentZooming?: string;
}
export interface ICanvasRect {
	x: number;
	y: number;
	width: number;
	height: number;
}
export interface WebGLContextEventMap {
	"webglcontextlost": WebGLContextEvent;
	"webglcontextrestore": WebGLContextEvent;
}
/**
 * Common interface for HTMLCanvasElement, OffscreenCanvas, and other custom canvas classes.
 * @extends PixiMixins.ICanvas
 * @extends Partial<EventTarget>
 * @memberof environment
 */
export interface ICanvas extends PixiMixins.ICanvas, Partial<EventTarget> {
	/** Width of the canvas. */
	width: number;
	/** Height of the canvas. */
	height: number;
	/**
	 * Get rendering context of the canvas.
	 * @param {ContextIds} contextId - The identifier of the type of context to create.
	 * @param {ContextSettings} options - The options for creating context.
	 * @returns {RenderingContext | null} The created context, or null if contextId is not supported.
	 */
	getContext(contextId: "2d", options?: ICanvasRenderingContext2DSettings): ICanvasRenderingContext2D | null;
	getContext(contextId: "bitmaprenderer", options?: ImageBitmapRenderingContextSettings): ImageBitmapRenderingContext | null;
	getContext(contextId: "webgl" | "experimental-webgl", options?: WebGLContextAttributes): WebGLRenderingContext | null;
	getContext(contextId: "webgl2" | "experimental-webgl2", options?: WebGLContextAttributes): WebGL2RenderingContext | null;
	getContext(contextId: "webgpu"): GPUCanvasContext | null;
	getContext(contextId: ContextIds, options?: ContextSettings): RenderingContext$1 | null;
	/**
	 * Get the content of the canvas as data URL.
	 * @param {string} [type] - A string indicating the image format. The default type is `image/png`;
	 *      that type is also used if the given type isn't supported.
	 * @param {string} [quality] - A number between 0 and 1 indicating the image quality to be used when
	 *      creating images using file formats that support lossy compression (such as `image/jpeg` or `image/webp`).
	 *      A user agent will use its default quality value if this option is not specified, or if the number
	 *      is outside the allowed range.
	 * @returns {string} A string containing the requested data URL.
	 */
	toDataURL?(type?: string, quality?: number): string;
	/**
	 * Creates a Blob from the content of the canvas.
	 * @param {(blob: Blob | null) => void} callback - A callback function with the resulting `Blob` object
	 *      as a single argument. `null` may be passed if the image cannot be created for any reason.
	 * @param {string} [type] - A string indicating the image format. The default type is `image/png`;
	 *      that type is also used if the given type isn't supported.
	 * @param {string} [quality] - A number between 0 and 1 indicating the image quality to be used when
	 *      creating images using file formats that support lossy compression (such as `image/jpeg` or `image/webp`).
	 *      A user agent will use its default quality value if this option is not specified, or if the number
	 *      is outside the allowed range.
	 * @returns {void}
	 */
	toBlob?(callback: (blob: Blob | null) => void, type?: string, quality?: number): void;
	/**
	 * Get the content of the canvas as Blob.
	 * @param {object} [options] - The options for creating Blob.
	 * @param {string} [options.type] - A string indicating the image format. The default type is `image/png`;
	 *      that type is also used if the given type isn't supported.
	 * @param {string} [options.quality] - A number between 0 and 1 indicating the image quality to be used when
	 *      creating images using file formats that support lossy compression (such as `image/jpeg` or `image/webp`).
	 *      A user agent will use its default quality value if this option is not specified, or if the number
	 *      is outside the allowed range.
	 * @returns {Promise<Blob>} A `Promise` returning a Blob object representing the image contained in the canvas.
	 */
	convertToBlob?(options?: {
		type?: string;
		quality?: number;
	}): Promise<Blob>;
	/**
	 * Adds the listener for the specified event.
	 * @method
	 * @param {string} type - The type of event to listen for.
	 * @param {EventListenerOrEventListenerObject} listener - The callback to invoke when the event is fired.
	 * @param {boolean | AddEventListenerOptions} options - The options for adding event listener.
	 * @returns {void}
	 */
	addEventListener?: {
		(type: string, listener: EventListenerOrEventListenerObject, options?: boolean | AddEventListenerOptions): void;
		<K extends keyof WebGLContextEventMap>(type: K, listener: (this: ICanvas, ev: WebGLContextEventMap[K]) => any, options?: boolean | AddEventListenerOptions): void;
	};
	/**
	 * Removes the listener for the specified event.
	 * @method
	 * @param {string} type - The type of event to listen for.
	 * @param {EventListenerOrEventListenerObject} listener - The callback to invoke when the event is fired.
	 * @param {boolean | EventListenerOptions} options - The options for removing event listener.
	 * @returns {void}
	 */
	removeEventListener?: {
		(type: string, listener: EventListenerOrEventListenerObject, options?: boolean | EventListenerOptions): void;
		<K extends keyof WebGLContextEventMap>(type: K, listener: (this: ICanvas, ev: WebGLContextEventMap[K]) => any, options?: boolean | EventListenerOptions): void;
	};
	/**
	 * Dispatches a event.
	 * @param {Event} event - The Event object to dispatch. Its Event.target property will be set to the current EventTarget.
	 * @returns {boolean} Returns false if event is cancelable, and at least one of the event handlers which received event
	 *                    called Event.preventDefault(). Otherwise true.
	 */
	dispatchEvent(event: Event): boolean;
	/** Parent node of the canvas. */
	readonly parentNode?: ICanvasParentNode | null;
	/** Style of the canvas. */
	readonly style?: ICanvasStyle;
	/**
	 * Get the position and the size of the canvas.
	 * @returns The smallest rectangle which contains the entire canvas.
	 */
	getBoundingClientRect?(): ICanvasRect;
}
/**
 * `extensions` is a global object that holds all the extensions registered with PixiJS.
 * PixiJS uses a this extensions architecture a lot to make the library more modular and
 * flexible.
 *
 * For example, if you want to add load a new type of asset, you can register a new
 * {@link assets.LoaderParser} with the `extensions` object.
 *
 * ```js
 * import { extensions, ExtensionType } from 'pixi.js';
 *
 * // create a custom asset loader
 * const customAssetLoader = {
 *    extension: {
 *        type: ExtensionType.LoadParser,
 *        name: 'custom-asset-loader',
 *    },
 *    test(url) {
 *       // check if this new loader should be used...
 *    },
 *    load(url) {
 *        // load the asset...
 *    },
 * };
 *
 * // add the custom asset loader to pixi
 * extensions.add(customAssetLoader);
 * ```
 *
 * This would add the `customAssetLoader` to the list of available loaders that PixiJS can use.
 *
 * There are many different types of extensions, which are listed in {@link extensions.ExtensionType}.
 * @namespace extensions
 */
/**
 * Collection of valid extension types.
 * @memberof extensions
 */
export declare enum ExtensionType {
	/** extensions that are registered as Application plugins */
	Application = "application",
	/** extensions that are registered as WebGL render pipes */
	WebGLPipes = "webgl-pipes",
	/** extensions that are registered as WebGL render pipes adaptors */
	WebGLPipesAdaptor = "webgl-pipes-adaptor",
	/** extensions that are registered as WebGL render systems */
	WebGLSystem = "webgl-system",
	/** extensions that are registered as WebGPU render pipes */
	WebGPUPipes = "webgpu-pipes",
	/** extensions that are registered as WebGPU render pipes adaptors */
	WebGPUPipesAdaptor = "webgpu-pipes-adaptor",
	/** extensions that are registered as WebGPU render systems */
	WebGPUSystem = "webgpu-system",
	/** extensions that are registered as Canvas render pipes */
	CanvasSystem = "canvas-system",
	/** extensions that are registered as Canvas render pipes adaptors */
	CanvasPipesAdaptor = "canvas-pipes-adaptor",
	/** extensions that are registered as Canvas render systems */
	CanvasPipes = "canvas-pipes",
	/** extensions that combine the other Asset extensions */
	Asset = "asset",
	/** extensions that are used to load assets through Assets */
	LoadParser = "load-parser",
	/** extensions that are used to resolve asset urls through Assets */
	ResolveParser = "resolve-parser",
	/** extensions that are used to handle how urls are cached by Assets */
	CacheParser = "cache-parser",
	/** extensions that are used to add/remove available resources from Assets */
	DetectionParser = "detection-parser",
	/** extensions that are registered with the MaskEffectManager */
	MaskEffect = "mask-effect",
	/** A type of extension for creating a new advanced blend mode */
	BlendMode = "blend-mode",
	/** A type of extension that will be used to auto detect a resource type */
	TextureSource = "texture-source",
	/** A type of extension that will be used to auto detect an environment */
	Environment = "environment",
	/** A type of extension for building and triangulating custom shapes used in graphics. */
	ShapeBuilder = "shape-builder",
	/** A type of extension for creating custom batchers used in rendering. */
	Batcher = "batcher"
}
/**
 * The metadata for an extension.
 * @memberof extensions
 * @ignore
 */
export interface ExtensionMetadataDetails {
	/** The extension type, can be multiple types */
	type: ExtensionType | ExtensionType[];
	/** Optional. Some plugins provide an API name/property, to make them more easily accessible */
	name?: string;
	/** Optional, used for sorting the plugins in a particular order */
	priority?: number;
}
/**
 * The metadata for an extension.
 * @memberof extensions
 */
export type ExtensionMetadata = ExtensionType | ExtensionMetadataDetails;
/**
 * Format when registering an extension. Generally, the extension
 * should have these values as `extension` static property,
 * but you can override name or type by providing an object.
 * @memberof extensions
 */
interface ExtensionFormat {
	/** The extension type, can be multiple types */
	type: ExtensionType | ExtensionType[];
	/** Optional. Some plugins provide an API name/property, such as Renderer plugins */
	name?: string;
	/** Optional, used for sorting the plugins in a particular order */
	priority?: number;
	/** Reference to the plugin object/class */
	ref: any;
}
/**
 * Extension format that is used internally for registrations.
 * @memberof extensions
 * @ignore
 */
interface StrictExtensionFormat extends ExtensionFormat {
	/** The extension type, always expressed as multiple, even if a single */
	type: ExtensionType[];
}
export type ExtensionHandler = (extension: StrictExtensionFormat) => void;
/**
 * Get the priority for an extension.
 * @ignore
 * @param ext - Any extension
 * @param defaultPriority - Fallback priority if none is defined.
 * @returns The priority for the extension.
 * @memberof extensions
 */
export declare const normalizeExtensionPriority: (ext: ExtensionFormat | any, defaultPriority: number) => number;
/**
 * Global registration of all PixiJS extensions. One-stop-shop for extensibility.
 *
 * Import the `extensions` object and use it to register new functionality via the described methods below.
 * ```js
 * import { extensions } from 'pixi.js';
 *
 * // register a new extension
 * extensions.add(myExtension);
 * ```
 * @property {Function} remove - Remove extensions from PixiJS.
 * @property {Function} add - Register new extensions with PixiJS.
 * @property {Function} handle - Internal method to handle extensions by name.
 * @property {Function} handleByMap - Handle a type, but using a map by `name` property.
 * @property {Function} handleByNamedList - Handle a type, but using a list of extensions with a `name` property.
 * @property {Function} handleByList - Handle a type, but using a list of extensions.
 * @memberof extensions
 */
export declare const extensions: {
	/** @ignore */
	_addHandlers: Partial<Record<ExtensionType, ExtensionHandler>>;
	/** @ignore */
	_removeHandlers: Partial<Record<ExtensionType, ExtensionHandler>>;
	/** @ignore */
	_queue: Partial<Record<ExtensionType, StrictExtensionFormat[]>>;
	/**
	 * Remove extensions from PixiJS.
	 * @param extensions - Extensions to be removed.
	 * @returns {extensions} For chaining.
	 */
	remove(...extensions: Array<ExtensionFormat | any>): any;
	/**
	 * Register new extensions with PixiJS.
	 * @param extensions - The spread of extensions to add to PixiJS.
	 * @returns {extensions} For chaining.
	 */
	add(...extensions: Array<ExtensionFormat | any>): any;
	/**
	 * Internal method to handle extensions by name.
	 * @param type - The extension type.
	 * @param onAdd  - Function handler when extensions are added/registered {@link StrictExtensionFormat}.
	 * @param onRemove  - Function handler when extensions are removed/unregistered {@link StrictExtensionFormat}.
	 * @returns {extensions} For chaining.
	 */
	handle(type: ExtensionType, onAdd: ExtensionHandler, onRemove: ExtensionHandler): any;
	/**
	 * Handle a type, but using a map by `name` property.
	 * @param type - Type of extension to handle.
	 * @param map - The object map of named extensions.
	 * @returns {extensions} For chaining.
	 */
	handleByMap(type: ExtensionType, map: Record<string, any>): any;
	/**
	 * Handle a type, but using a list of extensions with a `name` property.
	 * @param type - Type of extension to handle.
	 * @param map - The array of named extensions.
	 * @param defaultPriority - Fallback priority if none is defined.
	 * @returns {extensions} For chaining.
	 */
	handleByNamedList(type: ExtensionType, map: {
		name: string;
		value: any;
	}[], defaultPriority?: number): any;
	/**
	 * Handle a type, but using a list of extensions.
	 * @param type - Type of extension to handle.
	 * @param list - The list of extensions.
	 * @param defaultPriority - The default priority to use if none is specified.
	 * @returns {extensions} For chaining.
	 */
	handleByList(type: ExtensionType, list: any[], defaultPriority?: number): any;
};
export interface CanvasSourceOptions extends TextureSourceOptions<ICanvas> {
	/** should the canvas be resized to preserve its screen width and height regardless of the resolution of the renderer */
	autoDensity?: boolean;
	/** if true, this canvas will be set up to be transparent where possible */
	transparent?: boolean;
}
export declare class CanvasSource extends TextureSource<ICanvas> {
	static extension: ExtensionMetadata;
	uploadMethodId: string;
	autoDensity: boolean;
	transparent: boolean;
	private _context2D;
	constructor(options: CanvasSourceOptions);
	resizeCanvas(): void;
	resize(width?: number, height?: number, resolution?: number): boolean;
	static test(resource: any): resource is ICanvas;
	/**
	 * Returns the 2D rendering context for the canvas.
	 * Caches the context after creating it.
	 * @returns The 2D rendering context of the canvas.
	 */
	get context2D(): CanvasRenderingContext2D;
}
export type ImageResource = ImageBitmap | HTMLCanvasElement | OffscreenCanvas | ICanvas | VideoFrame | HTMLImageElement | HTMLVideoElement;
export declare class ImageSource extends TextureSource<ImageResource> {
	static extension: ExtensionMetadata;
	uploadMethodId: string;
	constructor(options: TextureSourceOptions<ImageResource>);
	static test(resource: any): resource is ImageResource;
}
export type TextureResourceOrOptions = ImageResource | TextureSourceOptions<ImageResource> | BufferSourceOptions | CanvasSourceOptions;
/**
 * @param options
 * @deprecated since v8.2.0
 * @see TextureSource.from
 */
export declare function autoDetectSource(options?: TextureResourceOrOptions): TextureSource;
export declare function resourceToTexture(options?: TextureResourceOrOptions, skipCache?: boolean): Texture;
/**
 * Helper function that creates a returns Texture based on the source you provide.
 * The source should be loaded and ready to go. If not its best to grab the asset using Assets.
 * @param id - String or Source to create texture from
 * @param skipCache - Skip adding the texture to the cache
 * @returns The texture based on the Id provided
 */
export declare function textureFrom(id: TextureSourceLike, skipCache?: boolean): Texture;
/**
 * options for creating a new TextureSource
 * @memberof rendering
 */
export interface TextureSourceOptions<T extends Record<string, any> = any> extends TextureStyleOptions {
	/**
	 * the resource that will be uploaded to the GPU. This is where we get our pixels from
	 * eg an ImageBimt / Canvas / Video etc
	 */
	resource?: T;
	/** the pixel width of this texture source. This is the REAL pure number, not accounting resolution */
	width?: number;
	/** the pixel height of this texture source. This is the REAL pure number, not accounting resolution */
	height?: number;
	/** the resolution of the texture. */
	resolution?: number;
	/** the format that the texture data has */
	format?: TEXTURE_FORMATS;
	/**
	 * Used by internal textures
	 * @ignore
	 */
	sampleCount?: number;
	/**
	 * Only really affects RenderTextures.
	 * Should we use antialiasing for this texture. It will look better, but may impact performance as a
	 * Blit operation will be required to resolve the texture.
	 */
	antialias?: boolean;
	/** how many dimensions does this texture have? currently v8 only supports 2d */
	dimensions?: TEXTURE_DIMENSIONS;
	/** The number of mip levels to generate for this texture. this is  overridden if autoGenerateMipmaps is true */
	mipLevelCount?: number;
	/**
	 * Should we auto generate mipmaps for this texture? This will automatically generate mipmaps
	 * for this texture when uploading to the GPU. Mipmapped textures take up more memory, but
	 * can look better when scaled down.
	 *
	 * For performance reasons, it is recommended to NOT use this with RenderTextures, as they are often updated every frame.
	 * If you do, make sure to call `updateMipmaps` after you update the texture.
	 */
	autoGenerateMipmaps?: boolean;
	/** the alpha mode of the texture */
	alphaMode?: ALPHA_MODES;
	/** optional label, can be used for debugging */
	label?: string;
	/** If true, the Garbage Collector will unload this texture if it is not used after a period of time */
	autoGarbageCollect?: boolean;
}
/**
 * A TextureSource stores the information that represents an image.
 * All textures have require TextureSource, which contains information about the source.
 * Therefore you can have many textures all using a single TextureSource (eg a sprite sheet)
 *
 * This is an class is extended depending on the source of the texture.
 * Eg if you are using an an image as your resource, then an ImageSource is used.
 * @memberof rendering
 * @typeParam T - The TextureSource's Resource type.
 */
export declare class TextureSource<T extends Record<string, any> = any> extends EventEmitter<{
	change: BindResource;
	update: TextureSource;
	unload: TextureSource;
	destroy: TextureSource;
	resize: TextureSource;
	styleChange: TextureSource;
	updateMipmaps: TextureSource;
	error: Error;
}> implements BindResource {
	protected readonly options: TextureSourceOptions<T>;
	/** The default options used when creating a new TextureSource. override these to add your own defaults */
	static defaultOptions: TextureSourceOptions;
	/** unique id for this Texture source */
	readonly uid: number;
	/** optional label, can be used for debugging */
	label: string;
	/**
	 * The resource type used by this TextureSource. This is used by the bind groups to determine
	 * how to handle this resource.
	 * @ignore
	 * @internal
	 */
	readonly _resourceType = "textureSource";
	/**
	 * i unique resource id, used by the bind group systems.
	 * This can change if the texture is resized or its resource changes
	 */
	_resourceId: number;
	/**
	 * this is how the backends know how to upload this texture to the GPU
	 * It changes depending on the resource type. Classes that extend TextureSource
	 * should override this property.
	 * @ignore
	 * @internal
	 */
	uploadMethodId: string;
	_resolution: number;
	/** the pixel width of this texture source. This is the REAL pure number, not accounting resolution */
	pixelWidth: number;
	/** the pixel height of this texture source. This is the REAL pure number, not accounting resolution */
	pixelHeight: number;
	/**
	 * the width of this texture source, accounting for resolution
	 * eg pixelWidth 200, resolution 2, then width will be 100
	 */
	width: number;
	/**
	 * the height of this texture source, accounting for resolution
	 * eg pixelHeight 200, resolution 2, then height will be 100
	 */
	height: number;
	/**
	 * the resource that will be uploaded to the GPU. This is where we get our pixels from
	 * eg an ImageBimt / Canvas / Video etc
	 */
	resource: T;
	/**
	 * The number of samples of a multisample texture. This is always 1 for non-multisample textures.
	 * To enable multisample for a texture, set antialias to true
	 * @internal
	 * @ignore
	 */
	sampleCount: number;
	/** The number of mip levels to generate for this texture. this is  overridden if autoGenerateMipmaps is true */
	mipLevelCount: number;
	/**
	 * Should we auto generate mipmaps for this texture? This will automatically generate mipmaps
	 * for this texture when uploading to the GPU. Mipmapped textures take up more memory, but
	 * can look better when scaled down.
	 *
	 * For performance reasons, it is recommended to NOT use this with RenderTextures, as they are often updated every frame.
	 * If you do, make sure to call `updateMipmaps` after you update the texture.
	 */
	autoGenerateMipmaps: boolean;
	/** the format that the texture data has */
	format: TEXTURE_FORMATS;
	/** how many dimensions does this texture have? currently v8 only supports 2d */
	dimension: TEXTURE_DIMENSIONS;
	/** the alpha mode of the texture */
	alphaMode: ALPHA_MODES;
	private _style;
	/**
	 * Only really affects RenderTextures.
	 * Should we use antialiasing for this texture. It will look better, but may impact performance as a
	 * Blit operation will be required to resolve the texture.
	 */
	antialias: boolean;
	/**
	 * Has the source been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	/**
	 * Used by automatic texture Garbage Collection, stores last GC tick when it was bound
	 * @protected
	 */
	_touched: number;
	/**
	 * Used by the batcher to build texture batches. faster to have the variable here!
	 * @protected
	 */
	_batchTick: number;
	/**
	 * A temporary batch location for the texture batching. Here for performance reasons only!
	 * @protected
	 */
	_textureBindLocation: number;
	isPowerOfTwo: boolean;
	/** If true, the Garbage Collector will unload this texture if it is not used after a period of time */
	autoGarbageCollect: boolean;
	/**
	 * used internally to know where a texture came from. Usually assigned by the asset loader!
	 * @ignore
	 */
	_sourceOrigin: string;
	/**
	 * @param options - options for creating a new TextureSource
	 */
	constructor(options?: TextureSourceOptions<T>);
	/** returns itself */
	get source(): TextureSource;
	/** the style of the texture */
	get style(): TextureStyle;
	set style(value: TextureStyle);
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	get addressMode(): WRAP_MODE;
	set addressMode(value: WRAP_MODE);
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	get repeatMode(): WRAP_MODE;
	set repeatMode(value: WRAP_MODE);
	/** Specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
	get magFilter(): SCALE_MODE;
	set magFilter(value: SCALE_MODE);
	/** Specifies the sampling behavior when the sample footprint is larger than one texel. */
	get minFilter(): SCALE_MODE;
	set minFilter(value: SCALE_MODE);
	/** Specifies behavior for sampling between mipmap levels. */
	get mipmapFilter(): SCALE_MODE;
	set mipmapFilter(value: SCALE_MODE);
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	get lodMinClamp(): number;
	set lodMinClamp(value: number);
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	get lodMaxClamp(): number;
	set lodMaxClamp(value: number);
	private _onStyleChange;
	/** call this if you have modified the texture outside of the constructor */
	update(): void;
	/** Destroys this texture source */
	destroy(): void;
	/**
	 * This will unload the Texture source from the GPU. This will free up the GPU memory
	 * As soon as it is required fore rendering, it will be re-uploaded.
	 */
	unload(): void;
	/** the width of the resource. This is the REAL pure number, not accounting resolution   */
	get resourceWidth(): number;
	/** the height of the resource. This is the REAL pure number, not accounting resolution */
	get resourceHeight(): number;
	/**
	 * the resolution of the texture. Changing this number, will not change the number of pixels in the actual texture
	 * but will the size of the texture when rendered.
	 *
	 * changing the resolution of this texture to 2 for example will make it appear twice as small when rendered (as pixel
	 * density will have increased)
	 */
	get resolution(): number;
	set resolution(resolution: number);
	/**
	 * Resize the texture, this is handy if you want to use the texture as a render texture
	 * @param width - the new width of the texture
	 * @param height - the new height of the texture
	 * @param resolution - the new resolution of the texture
	 * @returns - if the texture was resized
	 */
	resize(width?: number, height?: number, resolution?: number): boolean;
	/**
	 * Lets the renderer know that this texture has been updated and its mipmaps should be re-generated.
	 * This is only important for RenderTexture instances, as standard Texture instances will have their
	 * mipmaps generated on upload. You should call this method after you make any change to the texture
	 *
	 * The reason for this is is can be quite expensive to update mipmaps for a texture. So by default,
	 * We want you, the developer to specify when this action should happen.
	 *
	 * Generally you don't want to have mipmaps generated on Render targets that are changed every frame,
	 */
	updateMipmaps(): void;
	set wrapMode(value: WRAP_MODE);
	get wrapMode(): WRAP_MODE;
	set scaleMode(value: SCALE_MODE);
	/** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
	get scaleMode(): SCALE_MODE;
	/**
	 * Refresh check for isPowerOfTwo texture based on size
	 * @private
	 */
	protected _refreshPOT(): void;
	static test(_resource: any): any;
	/**
	 * A helper function that creates a new TextureSource based on the resource you provide.
	 * @param resource - The resource to create the texture source from.
	 */
	static from: (resource: TextureResourceOrOptions) => TextureSource;
}
/**
 * Buffer usage flags. they can be combined using the bitwise OR operator
 * eg : BufferUsage.VERTEX | BufferUsage.INDEX
 * @memberof rendering
 */
export declare enum BufferUsage {
	/**
	 * The buffer can be mapped for reading. (Example: calling mapAsync() with GPUMapMode.READ)
	 * May only be combined with COPY_DST.
	 */
	MAP_READ = 1,
	/**
	 * The buffer can be mapped for writing. (Example: calling mapAsync() with GPUMapMode.WRITE)
	 * May only be combined with COPY_SRC.
	 */
	MAP_WRITE = 2,
	/**
	 * The buffer can be used as the source of a copy operation.
	 * (Examples: as the source argument of a copyBufferToBuffer() or copyBufferToTexture() call.)
	 */
	COPY_SRC = 4,
	/**
	 * The buffer can be used as the destination of a copy or write operation.
	 * (Examples: as the destination argument of a copyBufferToBuffer() or
	 * copyTextureToBuffer() call, or as the target of a writeBuffer() call.)
	 */
	COPY_DST = 8,
	/** The buffer can be used as an index buffer. (Example: passed to setIndexBuffer().) */
	INDEX = 16,
	/** The buffer can be used as a vertex buffer. (Example: passed to setVertexBuffer().) */
	VERTEX = 32,
	/**
	 * The buffer can be used as a uniform buffer.
	 * (Example: as a bind group entry for a GPUBufferBindingLayout with a buffer.type of "uniform".)
	 */
	UNIFORM = 64,
	/**
	 * The buffer can be used as a storage buffer.
	 * (Example: as a bind group entry for a GPUBufferBindingLayout with a buffer.type of "storage" or "read-only-storage".)
	 */
	STORAGE = 128,
	/**
	 * The buffer can be used as to store indirect command arguments.
	 * (Examples: as the indirectBuffer argument of a drawIndirect() or dispatchWorkgroupsIndirect() call.)
	 */
	INDIRECT = 256,
	/**
	 * The buffer can be used to capture query results.
	 * (Example: as the destination argument of a resolveQuerySet() call.)
	 */
	QUERY_RESOLVE = 512,
	/** the buffer will not be updated frequently */
	STATIC = 1024
}
/** All the various typed arrays that exist in js */
export type TypedArray = Int8Array | Uint8Array | Int16Array | Uint16Array | Int32Array | Uint32Array | Uint8ClampedArray | Float32Array | Float64Array;
/** Options for creating a buffer */
export interface BufferOptions {
	/**
	 * the data to initialize the buffer with, this can be a typed array,
	 * or a regular number array. If it is a number array, it will be converted to a Float32Array
	 */
	data?: TypedArray | number[];
	/** the size of the buffer in bytes, if not supplied, it will be inferred from the data */
	size?: number;
	/** the usage of the buffer, see {@link rendering.BufferUsage} */
	usage: number;
	/** a label for the buffer, this is useful for debugging */
	label?: string;
	/**
	 * should the GPU buffer be shrunk when the data becomes smaller?
	 * changing this will cause the buffer to be destroyed and a new one created on the GPU
	 * this can be expensive, especially if the buffer is already big enough!
	 * setting this to false will prevent the buffer from being shrunk. This will yield better performance
	 * if you are constantly setting data that is changing size often.
	 * @default true
	 */
	shrinkToFit?: boolean;
}
export interface BufferDescriptor {
	label?: string;
	size: GPUSize64;
	usage: BufferUsage;
	mappedAtCreation?: boolean;
}
/**
 * A wrapper for a WebGPU/WebGL Buffer.
 * In PixiJS, the Buffer class is used to manage the data that is sent to the GPU rendering pipeline.
 * It abstracts away the underlying GPU buffer and provides an interface for uploading typed arrays or other data to the GPU,
 * They are used in the following places:
 * <br><br>
 * .1. {@link Geometry} as attribute data or index data for geometry
 * <br>
 * .2. {@link UniformGroup} as an underlying buffer for uniform data
 * <br>
 * .3. {@link BufferResource} as an underlying part of a buffer used directly by the GPU program
 * <br>
 *
 * It is important to note that you must provide a usage type when creating a buffer. This is because
 * the underlying GPU buffer needs to know how it will be used. For example, if you are creating a buffer
 * to hold vertex data, you would use `BufferUsage.VERTEX`. This will tell the GPU that this buffer will be
 * used as a vertex buffer. This is important because it will affect how you can use the buffer.
 *
 * Buffers are updated by calling the {@link Buffer.update} method. This immediately updates the buffer on the GPU.
 * Be mindful of calling this more often than you need to. It is recommended to update buffers only when needed.
 *
 * In WebGPU, a GPU buffer cannot resized. This limitation is abstracted away, but know that resizing a buffer means
 * creating a brand new one and destroying the old, so it is best to limit this if possible.
 * @example
 *
 * const buffer = new Buffer({
 *     data: new Float32Array([1, 2, 3, 4]),
 *     usage: BufferUsage.VERTEX,
 * });
 * @memberof rendering
 */
declare class Buffer$1 extends EventEmitter<{
	change: BindResource;
	update: Buffer$1;
	destroy: Buffer$1;
}> implements BindResource {
	/**
	 * emits when the underlying buffer has changed shape (i.e. resized)
	 * letting the renderer know that it needs to discard the old buffer on the GPU and create a new one
	 * @event change
	 */
	/**
	 * emits when the underlying buffer data has been updated. letting the renderer know
	 * that it needs to update the buffer on the GPU
	 * @event update
	 */
	/**
	 * emits when the buffer is destroyed. letting the renderer know that it needs to destroy the buffer on the GPU
	 * @event destroy
	 */
	/** a unique id for this uniform group used through the renderer */
	readonly uid: number;
	/**
	 * a resource type, used to identify how to handle it when its in a bind group / shader resource
	 * @internal
	 * @ignore
	 */
	readonly _resourceType = "buffer";
	/**
	 * the resource id used internally by the renderer to build bind group keys
	 * @internal
	 * @ignore
	 */
	_resourceId: number;
	/**
	 * used internally to know if a uniform group was used in the last render pass
	 * @internal
	 * @ignore
	 */
	_touched: number;
	/**
	 * a description of the buffer and how it should be set up on the GPU
	 * @internal
	 * @ignore
	 */
	readonly descriptor: BufferDescriptor;
	/**
	 * @internal
	 * @ignore
	 */
	_updateID: number;
	/**
	 * @internal
	 * @ignore
	 */
	_updateSize: number;
	private _data;
	private _dataInt32;
	/**
	 * should the GPU buffer be shrunk when the data becomes smaller?
	 * changing this will cause the buffer to be destroyed and a new one created on the GPU
	 * this can be expensive, especially if the buffer is already big enough!
	 * setting this to false will prevent the buffer from being shrunk. This will yield better performance
	 * if you are constantly setting data that is changing size often.
	 * @default true
	 */
	shrinkToFit: boolean;
	/**
	 * Has the buffer been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	/**
	 * Creates a new Buffer with the given options
	 * @param options - the options for the buffer
	 */
	constructor(options: BufferOptions);
	/** the data in the buffer */
	get data(): TypedArray;
	set data(value: TypedArray);
	get dataInt32(): Int32Array;
	/** whether the buffer is static or not */
	get static(): boolean;
	set static(value: boolean);
	/**
	 * Sets the data in the buffer to the given value. This will immediately update the buffer on the GPU.
	 * If you only want to update a subset of the buffer, you can pass in the size of the data.
	 * @param value - the data to set
	 * @param size - the size of the data in bytes
	 * @param syncGPU - should the buffer be updated on the GPU immediately?
	 */
	setDataWithSize(value: TypedArray, size: number, syncGPU: boolean): void;
	/**
	 * updates the buffer on the GPU to reflect the data in the buffer.
	 * By default it will update the entire buffer. If you only want to update a subset of the buffer,
	 * you can pass in the size of the buffer to update.
	 * @param sizeInBytes - the new size of the buffer in bytes
	 */
	update(sizeInBytes?: number): void;
	/** Destroys the buffer */
	destroy(): void;
}
export interface BufferSourceOptions extends TextureSourceOptions<TypedArray | ArrayBuffer> {
	width: number;
	height: number;
}
export declare class BufferImageSource extends TextureSource<TypedArray | ArrayBuffer> {
	static extension: ExtensionMetadata;
	uploadMethodId: string;
	constructor(options: BufferSourceOptions);
	static test(resource: any): resource is TypedArray | ArrayBuffer;
}
/**
 * Class controls uv mapping from Texture normal space to BaseTexture normal space.
 *
 * Takes `trim` and `rotate` into account. May contain clamp settings for Meshes and TilingSprite.
 *
 * Can be used in Texture `uvMatrix` field, or separately, you can use different clamp settings on the same texture.
 * If you want to add support for texture region of certain feature or filter, that's what you're looking for.
 *
 * Takes track of Texture changes through `_lastTextureID` private field.
 * Use `update()` method call to track it from outside.
 * @see Texture
 * @see Mesh
 * @see TilingSprite
 * @memberof rendering
 */
export declare class TextureMatrix {
	/**
	 * Matrix operation that converts texture region coords to texture coords
	 * @readonly
	 */
	mapCoord: Matrix;
	/**
	 * Changes frame clamping
	 * Works with TilingSprite and Mesh
	 * Change to 1.5 if you texture has repeated right and bottom lines, that leads to smoother borders
	 * @default 0
	 */
	clampOffset: number;
	/**
	 * Changes frame clamping
	 * Works with TilingSprite and Mesh
	 * Change to -0.5 to add a pixel to the edge, recommended for transparent trimmed textures in atlas
	 * @default 0.5
	 */
	clampMargin: number;
	/**
	 * Clamp region for normalized coords, left-top pixel center in xy , bottom-right in zw.
	 * Calculated based on clampOffset.
	 */
	readonly uClampFrame: Float32Array;
	/** Normalized clamp offset. Calculated based on clampOffset. */
	readonly uClampOffset: Float32Array;
	/**
	 * Tracks Texture frame changes.
	 * @ignore
	 */
	_updateID: number;
	/**
	 * Tracks Texture frame changes.
	 * @protected
	 */
	protected _textureID: number;
	protected _texture: Texture;
	/**
	 * If texture size is the same as baseTexture.
	 * @default false
	 * @readonly
	 */
	isSimple: boolean;
	/**
	 * @param texture - observed texture
	 * @param clampMargin - Changes frame clamping, 0.5 by default. Use -0.5 for extra border.
	 */
	constructor(texture: Texture, clampMargin?: number);
	/** Texture property. */
	get texture(): Texture;
	set texture(value: Texture);
	/**
	 * Multiplies uvs array to transform
	 * @param uvs - mesh uvs
	 * @param [out=uvs] - output
	 * @returns - output
	 */
	multiplyUvs(uvs: Float32Array, out?: Float32Array): Float32Array;
	/**
	 * Updates matrices if texture was changed
	 * @returns - whether or not it was updated
	 */
	update(): boolean;
}
/**
 * Stores the width of the non-scalable borders, for example when used with {@link scene.NineSlicePlane} texture.
 * @memberof rendering
 */
export interface TextureBorders {
	/** left border in pixels */
	left: number;
	/** top border in pixels */
	top: number;
	/** right border in pixels */
	right: number;
	/** bottom border in pixels */
	bottom: number;
}
/**
 * The UVs data structure for a texture.
 * @memberof rendering
 */
export type UVs = {
	x0: number;
	y0: number;
	x1: number;
	y1: number;
	x2: number;
	y2: number;
	x3: number;
	y3: number;
};
/**
 * The options that can be passed to a new Texture
 * @memberof rendering
 */
export interface TextureOptions<TextureSourceType extends TextureSource = TextureSource> {
	/** the underlying texture data that this texture will use  */
	source?: TextureSourceType;
	/** optional label, for debugging */
	label?: string;
	/** The rectangle frame of the texture to show */
	frame?: Rectangle;
	/** The area of original texture */
	orig?: Rectangle;
	/** Trimmed rectangle of original texture */
	trim?: Rectangle;
	/** Default anchor point used for sprite placement / rotation */
	defaultAnchor?: {
		x: number;
		y: number;
	};
	/** Default borders used for 9-slice scaling {@link NineSlicePlane}*/
	defaultBorders?: TextureBorders;
	/** indicates how the texture was rotated by texture packer. See {@link groupD8} */
	rotate?: number;
	/**
	 * Set to true if you plan on modifying this texture's frame, UVs, or swapping its source at runtime.
	 * This is false by default as it improves performance. Generally, it's recommended to create new
	 * textures and swap those rather than modifying an existing texture's properties unless you are
	 * working with a dynamic frames.
	 * Not setting this to true when modifying the texture can lead to visual artifacts.
	 *
	 * If this is false and you modify the texture, you can manually update the sprite's texture by calling
	 * `sprite.onViewUpdate()`.
	 */
	dynamic?: boolean;
}
export interface BindableTexture {
	source: TextureSource;
}
export type TextureSourceLike = TextureSource | TextureResourceOrOptions | string;
/**
 * A texture stores the information that represents an image or part of an image.
 *
 * A texture must have a loaded resource passed to it to work. It does not contain any
 * loading mechanisms.
 *
 * The Assets class can be used to load an texture from a file. This is the recommended
 * way as it will handle the loading and caching for you.
 *
 * ```js
 *
 * const texture = await Assets.load('assets/image.png');
 *
 * // once Assets has loaded the image it will be available via the from method
 * const sameTexture = Texture.from('assets/image.png');
 * // another way to access the texture once loaded
 * const sameAgainTexture = Asset.get('assets/image.png');
 *
 * const sprite1 = new Sprite(texture);
 *
 * ```
 *
 * It cannot be added to the display list directly; instead use it as the texture for a Sprite.
 * If no frame is provided for a texture, then the whole image is used.
 *
 * You can directly create a texture from an image and then reuse it multiple times like this :
 *
 * ```js
 * import { Sprite, Texture } from 'pixi.js';
 *
 * const texture = await Assets.load('assets/image.png');
 * const sprite1 = new Sprite(texture);
 * const sprite2 = new Sprite(texture);
 * ```
 *
 * If you didn't pass the texture frame to constructor, it enables `noFrame` mode:
 * it subscribes on baseTexture events, it automatically resizes at the same time as baseTexture.
 * @memberof rendering
 * @class
 */
export declare class Texture<TextureSourceType extends TextureSource = TextureSource> extends EventEmitter<{
	update: Texture;
	destroy: Texture;
}> implements BindableTexture {
	/**
	 * Helper function that creates a returns Texture based on the source you provide.
	 * The source should be loaded and ready to go. If not its best to grab the asset using Assets.
	 * @param id - String or Source to create texture from
	 * @param skipCache - Skip adding the texture to the cache
	 * @returns The texture based on the Id provided
	 */
	static from: (id: TextureSourceLike, skipCache?: boolean) => Texture;
	/** label used for debugging */
	label?: string;
	/** unique id for this texture */
	readonly uid: number;
	/**
	 * Has the texture been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	_source: TextureSourceType;
	/**
	 * Indicates whether the texture is rotated inside the atlas
	 * set to 2 to compensate for texture packer rotation
	 * set to 6 to compensate for spine packer rotation
	 * can be used to rotate or mirror sprites
	 * See {@link maths.groupD8} for explanation
	 */
	readonly rotate: number;
	/** A uvs object based on the given frame and the texture source */
	readonly uvs: UVs;
	/**
	 * Anchor point that is used as default if sprite is created with this texture.
	 * Changing the `defaultAnchor` at a later point of time will not update Sprite's anchor point.
	 * @default {0,0}
	 */
	readonly defaultAnchor?: {
		x: number;
		y: number;
	};
	/**
	 * Default width of the non-scalable border that is used if 9-slice plane is created with this texture.
	 * @since 7.2.0
	 * @see scene.NineSliceSprite
	 */
	readonly defaultBorders?: TextureBorders;
	/**
	 * This is the area of the BaseTexture image to actually copy to the Canvas / WebGL when rendering,
	 * irrespective of the actual frame size or placement (which can be influenced by trimmed texture atlases)
	 */
	readonly frame: Rectangle;
	/** This is the area of original texture, before it was put in atlas. */
	readonly orig: Rectangle;
	/**
	 * This is the trimmed area of original texture, before it was put in atlas
	 * Please call `updateUvs()` after you change coordinates of `trim` manually.
	 */
	readonly trim: Rectangle;
	/**
	 * Does this Texture have any frame data assigned to it?
	 *
	 * This mode is enabled automatically if no frame was passed inside constructor.
	 *
	 * In this mode texture is subscribed to baseTexture events, and fires `update` on any change.
	 *
	 * Beware, after loading or resize of baseTexture event can fired two times!
	 * If you want more control, subscribe on baseTexture itself.
	 * @example
	 * texture.on('update', () => {});
	 */
	noFrame: boolean;
	/**
	 * Set to true if you plan on modifying the uvs of this texture.
	 * When this is the case, sprites and other objects using the texture will
	 * make sure to listen for changes to the uvs and update their vertices accordingly.
	 */
	dynamic: boolean;
	private _textureMatrix;
	/** is it a texture? yes! used for type checking */
	readonly isTexture = true;
	/**
	 * @param {rendering.TextureOptions} options - Options for the texture
	 */
	constructor({ source, label, frame, orig, trim, defaultAnchor, defaultBorders, rotate, dynamic }?: TextureOptions<TextureSourceType>);
	set source(value: TextureSourceType);
	/** the underlying source of the texture (equivalent of baseTexture in v7) */
	get source(): TextureSourceType;
	/** returns a TextureMatrix instance for this texture. By default, that object is not created because its heavy. */
	get textureMatrix(): TextureMatrix;
	/** The width of the Texture in pixels. */
	get width(): number;
	/** The height of the Texture in pixels. */
	get height(): number;
	/** Call this function when you have modified the frame of this texture. */
	updateUvs(): void;
	/**
	 * Destroys this texture
	 * @param destroySource - Destroy the source when the texture is destroyed.
	 */
	destroy(destroySource?: boolean): void;
	/**
	 * Call this if you have modified the `texture outside` of the constructor.
	 *
	 * If you have modified this texture's source, you must separately call `texture.source.update()` to see those changes.
	 */
	update(): void;
	/** @deprecated since 8.0.0 */
	get baseTexture(): TextureSource;
	/** an Empty Texture used internally by the engine */
	static EMPTY: Texture;
	/** a White texture used internally by the engine */
	static WHITE: Texture<BufferImageSource>;
}
type TypedArray$1 = Float32Array | Uint32Array | Int32Array | Uint8Array;
/**
 * Flexible wrapper around `ArrayBuffer` that also provides typed array views on demand.
 * @memberof utils
 */
export declare class ViewableBuffer {
	/** The size of the buffer in bytes. */
	size: number;
	/** Underlying `ArrayBuffer` that holds all the data and is of capacity `this.size`. */
	rawBinaryData: ArrayBuffer;
	/** View on the raw binary data as a `Uint32Array`. */
	uint32View: Uint32Array;
	/** View on the raw binary data as a `Float32Array`. */
	float32View: Float32Array;
	uint16View: Uint16Array;
	private _int8View;
	private _uint8View;
	private _int16View;
	private _int32View;
	private _float64Array;
	private _bigUint64Array;
	/**
	 * @param length - The size of the buffer in bytes.
	 */
	constructor(length: number);
	/**
	 * @param arrayBuffer - The source array buffer.
	 */
	constructor(arrayBuffer: ArrayBuffer);
	/** View on the raw binary data as a `Int8Array`. */
	get int8View(): Int8Array;
	/** View on the raw binary data as a `Uint8Array`. */
	get uint8View(): Uint8Array;
	/**  View on the raw binary data as a `Int16Array`. */
	get int16View(): Int16Array;
	/** View on the raw binary data as a `Int32Array`. */
	get int32View(): Int32Array;
	/** View on the raw binary data as a `Float64Array`. */
	get float64View(): Float64Array;
	/** View on the raw binary data as a `BigUint64Array`. */
	get bigUint64View(): BigUint64Array;
	/**
	 * Returns the view of the given type.
	 * @param type - One of `int8`, `uint8`, `int16`,
	 *    `uint16`, `int32`, `uint32`, and `float32`.
	 * @returns - typed array of given type
	 */
	view(type: string): TypedArray$1;
	/** Destroys all buffer references. Do not use after calling this. */
	destroy(): void;
	/**
	 * Returns the size of the given type in bytes.
	 * @param type - One of `int8`, `uint8`, `int16`,
	 *   `uint16`, `int32`, `uint32`, and `float32`.
	 * @returns - size of the type in bytes
	 */
	static sizeOf(type: string): number;
}
/**
 * Various blend modes supported by Pixi
 * @memberof filters
 */
export type BLEND_MODES = "inherit" | "normal" | "add" | "multiply" | "screen" | "darken" | "lighten" | "erase" | "color-dodge" | "color-burn" | "linear-burn" | "linear-dodge" | "linear-light" | "hard-light" | "soft-light" | "pin-light" | "difference" | "exclusion" | "overlay" | "saturation" | "color" | "luminosity" | "normal-npm" | "add-npm" | "screen-npm" | "none" | "subtract" | "divide" | "vivid-light" | "hard-mix" | "negation" | "min" | "max";
/**
 * The map of blend modes supported by Pixi
 * @memberof rendering
 */
export declare const BLEND_TO_NPM: {
	normal: string;
	add: string;
	screen: string;
};
/**
 * The stencil operation to perform when using the stencil buffer
 * @memberof rendering
 */
export declare enum STENCIL_MODES {
	DISABLED = 0,
	RENDERING_MASK_ADD = 1,
	MASK_ACTIVE = 2,
	INVERSE_MASK_ACTIVE = 3,
	RENDERING_MASK_REMOVE = 4,
	NONE = 5
}
/**
 * The culling mode to use. It can be either `none`, `front` or `back`.
 * @memberof rendering
 */
export type CULL_MODES = "none" | "back" | "front";
/**
 * Used by the batcher to build texture batches. Holds list of textures and their respective locations.
 * @memberof rendering
 */
export declare class BatchTextureArray {
	/** Inside textures array. */
	textures: TextureSource[];
	/** Respective locations for textures. */
	ids: Record<number, number>;
	/** Number of filled elements. */
	count: number;
	constructor();
	/** Clear the textures and their locations. */
	clear(): void;
}
/**
 * The different topology types supported by the renderer used to describe how the geometry should be renderer
 * @memberof rendering
 */
export type Topology = "point-list" | "line-list" | "line-strip" | "triangle-list" | "triangle-strip";
/** @deprecated since 8.0.0 */
export declare const DRAW_MODES: {
	POINTS: string;
	LINES: string;
	LINE_STRIP: string;
	TRIANGLES: string;
	TRIANGLE_STRIP: string;
};
/**
 * The different types of vertex formats supported by the renderer
 * @memberof rendering
 */
export type VertexFormat = "uint8x2" | "uint8x4" | "sint8x2" | "sint8x4" | "unorm8x2" | "unorm8x4" | "snorm8x2" | "snorm8x4" | "uint16x2" | "uint16x4" | "sint16x2" | "sint16x4" | "unorm16x2" | "unorm16x4" | "snorm16x2" | "snorm16x4" | "float16x2" | "float16x4" | "float32" | "float32x2" | "float32x3" | "float32x4" | "uint32" | "uint32x2" | "uint32x3" | "uint32x4" | "sint32" | "sint32x2" | "sint32x3" | "sint32x4";
export type IndexBufferArray = Uint16Array | Uint32Array;
/**
 * The attribute data for a geometries attributes
 * @memberof rendering
 */
export interface Attribute {
	/** the buffer that this attributes data belongs to */
	buffer: Buffer$1;
	/** the format of the attribute */
	format?: VertexFormat;
	/** the stride of the data in the buffer - in bytes*/
	stride?: number;
	/** the offset of the attribute from the buffer, defaults to 0 - in bytes*/
	offset?: number;
	/** is this an instanced buffer? (defaults to false) */
	instance?: boolean;
	/** the number of elements to be rendered. If not specified, all vertices after the starting vertex will be drawn. */
	size?: number;
	/**
	 * the starting vertex in the geometry to start drawing from. If not specified,
	 *  drawing will start from the first vertex.
	 */
	start?: number;
	/**
	 * attribute divisor for instanced rendering. Note: this is a **WebGL-only** feature, the WebGPU renderer will
	 * issue a warning if one of the attributes has divisor set.
	 */
	divisor?: number;
}
type AttributeOption = Omit<Attribute, "buffer"> & {
	buffer: Buffer$1 | TypedArray | number[];
} | Buffer$1 | TypedArray | number[];
export type AttributeOptions = Record<string, AttributeOption>;
/**
 * the interface that describes the structure of the geometry
 * @memberof rendering
 */
export interface GeometryDescriptor {
	/** an optional label to easily identify the geometry */
	label?: string;
	/** the attributes that make up the geometry */
	attributes?: AttributeOptions;
	/** optional index buffer for this geometry */
	indexBuffer?: Buffer$1 | TypedArray | number[];
	/** the topology of the geometry, defaults to 'triangle-list' */
	topology?: Topology;
	instanceCount?: number;
}
/**
 * A Geometry is a low-level object that represents the structure of 2D shapes in terms of vertices and attributes.
 * It's a crucial component for rendering as it describes the shape and format of the data that will go through the shaders.
 * Essentially, a Geometry object holds the data you'd send to a GPU buffer.
 *
 * A geometry is basically made of two components:
 * <br>
 * <b>Attributes</b>: These are essentially arrays that define properties of the vertices like position, color,
 * texture coordinates, etc. They map directly to attributes in your vertex shaders.
 * <br>
 * <b>Indices</b>: An optional array that describes how the vertices are connected.
 * If not provided, vertices will be interpreted in the sequence they're given.
 * @example
 *
 * const geometry = new Geometry({
 *   attributes: {
 *     aPosition: [ // add some positions
 *       0, 0,
 *       0, 100,
 *       100, 100,
 *       100,   0,
 *     ],
 *     aUv: [ // add some uvs
 *       0, 0,
 *       0, 1,
 *       1, 1,
 *       1, 0,
 *     ]
 *   }
 * });
 * @memberof rendering
 * @class
 */
export declare class Geometry extends EventEmitter<{
	update: Geometry;
	destroy: Geometry;
}> {
	/** The topology of the geometry. */
	topology: Topology;
	/** The unique id of the geometry. */
	readonly uid: number;
	/** A record of the attributes of the geometry. */
	readonly attributes: Record<string, Attribute>;
	/** The buffers that the attributes use */
	readonly buffers: Buffer$1[];
	/** The index buffer of the geometry */
	indexBuffer: Buffer$1;
	/**
	 * the layout key will be generated by WebGPU all geometries that have the same structure
	 * will have the same layout key. This is used to cache the pipeline layout
	 * @internal
	 * @ignore
	 */
	_layoutKey: number;
	/** the instance count of the geometry to draw */
	instanceCount: number;
	private readonly _bounds;
	private _boundsDirty;
	/**
	 * Create a new instance of a geometry
	 * @param options - The options for the geometry.
	 */
	constructor(options?: GeometryDescriptor);
	protected onBufferUpdate(): void;
	/**
	 * Returns the requested attribute.
	 * @param id - The name of the attribute required
	 * @returns - The attribute requested.
	 */
	getAttribute(id: string): Attribute;
	/**
	 * Returns the index buffer
	 * @returns - The index buffer.
	 */
	getIndex(): Buffer$1;
	/**
	 * Returns the requested buffer.
	 * @param id - The name of the buffer required.
	 * @returns - The buffer requested.
	 */
	getBuffer(id: string): Buffer$1;
	/**
	 * Used to figure out how many vertices there are in this geometry
	 * @returns the number of vertices in the geometry
	 */
	getSize(): number;
	/**
	 * Adds an attribute to the geometry.
	 * @param name - The name of the attribute to add.
	 * @param attributeOption - The attribute option to add.
	 */
	addAttribute(name: string, attributeOption: AttributeOption): void;
	/**
	 * Adds an index buffer to the geometry.
	 * @param indexBuffer - The index buffer to add. Can be a Buffer, TypedArray, or an array of numbers.
	 */
	addIndex(indexBuffer: Buffer$1 | TypedArray | number[]): void;
	/** Returns the bounds of the geometry. */
	get bounds(): Bounds;
	/**
	 * destroys the geometry.
	 * @param destroyBuffers - destroy the buffers associated with this geometry
	 */
	destroy(destroyBuffers?: boolean): void;
}
export interface ExtractedAttributeData extends Omit<Attribute, "buffer"> {
	/** set where the shader location is for this attribute */
	location?: number;
}
/**
 * returns the attribute data from the program
 * @private
 * @param {WebGLProgram} [program] - the WebGL program
 * @param {WebGLRenderingContext} [gl] - the WebGL context
 * @returns {object} the attribute data for this program
 */
export declare function extractAttributesFromGlProgram(program: WebGLProgram, gl: WebGLRenderingContextBase, sortAttributes?: boolean): Record<string, ExtractedAttributeData>;
export interface GlAttributeData {
	type: string;
	size: number;
	location: number;
	name: string;
}
export interface GlUniformData {
	name: string;
	index: number;
	type: string;
	size: number;
	isArray: boolean;
	value: any;
}
export interface GlUniformBlockData {
	index: number;
	name: string;
	size: number;
	value?: TypedArray;
}
/**
 * The options for the gl program
 * @memberof rendering
 */
export interface GlProgramOptions {
	/** The fragment glsl shader source. */
	fragment: string;
	/** The vertex glsl shader source. */
	vertex: string;
	/** the name of the program, defaults to 'pixi-program' */
	name?: string;
	/** the preferred vertex precision for the shader, this may not be used if the device does not support it  */
	preferredVertexPrecision?: string;
	/** the preferred fragment precision for the shader, this may not be used if the device does not support it  */
	preferredFragmentPrecision?: string;
	transformFeedbackVaryings?: {
		names: string[];
		bufferMode: "separate" | "interleaved";
	};
}
/**
 * A wrapper for a WebGL Program. You can create one and then pass it to a shader.
 * This will manage the WebGL program that is compiled and uploaded to the GPU.
 *
 * To get the most out of this class, you should be familiar with glsl shaders and how they work.
 * @see https://developer.mozilla.org/en-US/docs/Web/API/WebGLProgram
 * @example
 *
 * // Create a new program
 * const program = new GlProgram({
 *   vertex: '...',
 *   fragment: '...',
 * });
 *
 *
 * There are a few key things that pixi shader will do for you automatically:
 * <br>
 * - If no precision is provided in the shader, it will be injected into the program source for you.
 * This precision will be taken form the options provided, if none is provided,
 * then the program will default to the defaultOptions.
 * <br>
 * - It will inject the program name into the shader source if none is provided.
 * <br>
 *  - It will set the program version to 300 es.
 *
 * For optimal usage and best performance, its best to reuse programs as much as possible.
 * You should use the {@link GlProgram.from} helper function to create programs.
 * @class
 * @memberof rendering
 */
export declare class GlProgram {
	/** The default options used by the program. */
	static defaultOptions: Partial<GlProgramOptions>;
	/** the fragment glsl shader source. */
	readonly fragment?: string;
	/** the vertex glsl shader source */
	readonly vertex?: string;
	/**
	 * attribute data extracted from the program once created this happens when the program is used for the first time
	 * @internal
	 * @ignore
	 */
	_attributeData: Record<string, ExtractedAttributeData>;
	/**
	 * uniform data extracted from the program once created this happens when the program is used for the first time
	 * @internal
	 * @ignore
	 */
	_uniformData: Record<string, GlUniformData>;
	/**
	 * uniform data extracted from the program once created this happens when the program is used for the first time
	 * @internal
	 * @ignore
	 */
	_uniformBlockData: Record<string, GlUniformBlockData>;
	/** details on how to use this program with transform feedback */
	transformFeedbackVaryings?: {
		names: string[];
		bufferMode: "separate" | "interleaved";
	};
	/**
	 * the key that identifies the program via its source vertex + fragment
	 * @internal
	 * @ignore
	 */
	readonly _key: number;
	/**
	 * Creates a shiny new GlProgram. Used by WebGL renderer.
	 * @param options - The options for the program.
	 */
	constructor(options: GlProgramOptions);
	/** destroys the program */
	destroy(): void;
	/**
	 * Helper function that creates a program for a given source.
	 * It will check the program cache if the program has already been created.
	 * If it has that one will be returned, if not a new one will be created and cached.
	 * @param options - The options for the program.
	 * @returns A program using the same source
	 */
	static from(options: GlProgramOptions): GlProgram;
}
export interface StructsAndGroups {
	groups: {
		group: number;
		binding: number;
		name: string;
		isUniform: boolean;
		type: string;
	}[];
	structs: {
		name: string;
		members: Record<string, string>;
	}[];
}
export declare function extractStructAndGroups(wgsl: string): StructsAndGroups;
/**
 * a WebGPU descriptions of how the program is laid out
 * @see https://gpuweb.github.io/gpuweb/#gpupipelinelayout
 * @memberof rendering
 */
export type ProgramPipelineLayoutDescription = GPUBindGroupLayoutEntry[][];
/**
 * a map the maps names of uniforms to group indexes
 * @memberof rendering
 */
export type ProgramLayout = Record<string, number>[];
/**
 * the program source
 * @memberof rendering
 */
export interface ProgramSource {
	/** The wgsl source code of the shader. */
	source: string;
	/** The main function to run in this shader */
	entryPoint?: string;
}
/**
 * The options for the gpu program
 * @memberof rendering
 */
export interface GpuProgramOptions {
	/**
	 * the name of the program, this is added to the label of the GPU Program created
	 * under the hood. Makes it much easier to debug!
	 */
	name?: string;
	/** The fragment glsl shader source. */
	fragment?: ProgramSource;
	/** The vertex glsl shader source. */
	vertex?: ProgramSource;
	/** The layout of the program. If not provided, it will be generated from the shader sources. */
	layout?: ProgramLayout;
	/** The gpu layout of the program. If not provided, it will be generated from the shader sources. */
	gpuLayout?: ProgramPipelineLayoutDescription;
}
/**
 * A wrapper for a WebGPU Program, specifically designed for the WebGPU renderer.
 * This class facilitates the creation and management of shader code that integrates with the WebGPU pipeline.
 *
 * To leverage the full capabilities of this class, familiarity with WGSL shaders is recommended.
 * @see https://gpuweb.github.io/gpuweb/#index
 * @example
 *
 * // Create a new program
 * const program = new GpuProgram({
 *   vertex: {
 *    source: '...',
 *    entryPoint: 'main',
 *   },
 *   fragment:{
 *    source: '...',
 *    entryPoint: 'main',
 *   },
 * });
 *
 *
 * Note: Both fragment and vertex shader sources can coexist within a single WGSL source file
 * this can make things a bit simpler.
 *
 * For optimal usage and best performance, it help to reuse programs whenever possible.
 * The {@link GpuProgram.from} helper function is designed for this purpose, utilizing an
 * internal cache to efficiently manage and retrieve program instances.
 * By leveraging this function, you can significantly reduce overhead and enhance the performance of your rendering pipeline.
 *
 * An important distinction between WebGL and WebGPU regarding program data retrieval:
 * While WebGL allows extraction of program information directly from its compiled state,
 * WebGPU does not offer such a capability. Therefore, in the context of WebGPU, we're required
 * to manually extract the program layout information from the source code itself.
 * @memberof rendering
 */
export declare class GpuProgram {
	/** The fragment glsl shader source. */
	readonly fragment?: ProgramSource;
	/** The vertex glsl shader source */
	readonly vertex?: ProgramSource;
	/**
	 * Mapping of uniform names to group indexes for organizing shader program uniforms.
	 * Automatically generated from shader sources if not provided.
	 * @example
	 * // Assuming a shader with two uniforms, `u_time` and `u_resolution`, grouped respectively:
	 * [
	 *   { "u_time": 0 },
	 *   { "u_resolution": 1 }
	 * ]
	 */
	readonly layout: ProgramLayout;
	/**
	 * Configuration for the WebGPU bind group layouts, detailing resource organization for the shader.
	 * Generated from shader sources if not explicitly provided.
	 * @example
	 * // Assuming a shader program that requires two bind groups:
	 * [
	 *   // First bind group layout entries
	 *   [{ binding: 0, visibility: GPUShaderStage.VERTEX, type: "uniform-buffer" }],
	 *   // Second bind group layout entries
	 *   [{ binding: 1, visibility: GPUShaderStage.FRAGMENT, type: "sampler" },
	 *    { binding: 2, visibility: GPUShaderStage.FRAGMENT, type: "sampled-texture" }]
	 * ]
	 */
	readonly gpuLayout: ProgramPipelineLayoutDescription;
	/**
	 * @internal
	 * @ignore
	 */
	_layoutKey: number;
	/**
	 * @internal
	 * @ignore
	 */
	_attributeLocationsKey: number;
	/** the structs and groups extracted from the shader sources */
	readonly structsAndGroups: StructsAndGroups;
	/**
	 * the name of the program, this is added to the label of the GPU Program created under the hood.
	 * Makes it much easier to debug!
	 */
	readonly name: string;
	private _attributeData;
	/** if true, the program will automatically assign global uniforms to group[0] */
	autoAssignGlobalUniforms: boolean;
	/** if true, the program will automatically assign local uniforms to group[1] */
	autoAssignLocalUniforms: boolean;
	/**
	 * Create a new GpuProgram
	 * @param options - The options for the gpu program
	 */
	constructor(options: GpuProgramOptions);
	private _generateProgramKey;
	get attributeData(): Record<string, ExtractedAttributeData>;
	/** destroys the program */
	destroy(): void;
	/**
	 * Helper function that creates a program for a given source.
	 * It will check the program cache if the program has already been created.
	 * If it has that one will be returned, if not a new one will be created and cached.
	 * @param options - The options for the program.
	 * @returns A program using the same source
	 */
	static from(options: GpuProgramOptions): GpuProgram;
}
/**
 * A record of {@link BindGroup}'s used by the shader.
 *
 * `Record<number, BindGroup>`
 * @memberof rendering
 */
export type ShaderGroups = Record<number, BindGroup>;
interface ShaderBase {
	/** The WebGL program used by the WebGL renderer. */
	glProgram?: GlProgram;
	/** The WebGPU program used by the WebGPU renderer. */
	gpuProgram?: GpuProgram;
	/**
	 * A number that uses two bits on whether the shader is compatible with the WebGL renderer and/or the WebGPU renderer.
	 * 0b00 - not compatible with either
	 * 0b01 - compatible with WebGL
	 * 0b10 - compatible with WebGPU
	 * This is automatically set based on if a {@link GlProgram} or {@link GpuProgram} is provided.
	 */
	compatibleRenderers?: number;
}
export interface GlShaderWith extends ShaderBase {
	/** The WebGL program used by the WebGL renderer. */
	glProgram: GlProgram;
}
export interface GpuShaderWith extends ShaderBase {
	/** The WebGPU program used by the WebGPU renderer. */
	gpuProgram: GpuProgram;
}
export interface ShaderWithGroupsDescriptor {
	/** A record of {@link BindGroup}'s used by the shader. */
	groups: ShaderGroups;
	/** an optional map of how to bind the groups. This is automatically generated by reading the WebGPU program */
	groupMap?: Record<string, Record<string, any>>;
}
interface ShaderWithResourcesDescriptor {
	/**
	 * A key value of uniform resources used by the shader.
	 * Under the hood pixi will look at the provided shaders and figure out where
	 * the resources are mapped. Its up to you to make sure the resource key
	 * matches the uniform name in the webGPU program. WebGL is a little more forgiving!
	 */
	resources?: Record<string, any>;
}
/**
 * A descriptor for a shader
 * @memberof rendering
 */
export type ShaderWith = GlShaderWith | GpuShaderWith;
/**
 * A descriptor for a shader with groups.
 * @memberof rendering
 */
export type ShaderWithGroups = ShaderWithGroupsDescriptor & ShaderWith;
export interface IShaderWithGroups extends ShaderWithGroupsDescriptor, ShaderBase {
}
/**
 * A descriptor for a shader with resources. This is an easier way to work with uniforms.
 * especially when you are not working with bind groups
 * @memberof rendering
 */
export type ShaderWithResources = ShaderWithResourcesDescriptor & ShaderWith;
export interface IShaderWithResources extends ShaderWithResourcesDescriptor, ShaderBase {
}
export type ShaderDescriptor = ShaderWithGroups & ShaderWithResources;
type GlShaderFromWith = {
	gpu?: GpuProgramOptions;
	gl: GlProgramOptions;
};
type GpuShaderFromWith = {
	gpu: GpuProgramOptions;
	gl?: GlProgramOptions;
};
export type ShaderFromGroups = (GlShaderFromWith | GpuShaderFromWith) & Omit<ShaderWithGroups, "glProgram" | "gpuProgram">;
export type ShaderFromResources = (GlShaderFromWith | GpuShaderFromWith) & Omit<ShaderWithResources, "glProgram" | "gpuProgram">;
/**
 * The Shader class is an integral part of the PixiJS graphics pipeline.
 * Central to rendering in PixiJS are two key elements: A [shader] and a [geometry].
 * The shader incorporates a {@link GlProgram} for WebGL or a {@link GpuProgram} for WebGPU,
 * instructing the respective technology on how to render the geometry.
 *
 * The primary goal of the Shader class is to offer a unified interface compatible with both WebGL and WebGPU.
 * When constructing a shader, you need to provide both a WebGL program and a WebGPU program due to the distinctions
 * between the two rendering engines. If only one is provided, the shader won't function with the omitted renderer.
 *
 * Both WebGL and WebGPU utilize the same resource object when passed into the shader.
 * Post-creation, the shader's interface remains consistent across both WebGL and WebGPU.
 * The sole distinction lies in whether a glProgram or a gpuProgram is employed.
 *
 * Modifying shader uniforms, which can encompass:
 *  - TextureSampler {@link TextureStyle}
 *  - TextureSource {@link TextureSource}
 *  - UniformsGroups {@link UniformGroup}
 * @example
 *
 * const shader = new Shader({
 *     glProgram: glProgram,
 *     gpuProgram: gpuProgram,
 *     resources: {
 *         uTexture: texture.source,
 *         uSampler: texture.sampler,
 *         uColor: [1, 0, 0, 1],
 *     },
 * });
 *
 * // update the uniforms
 * shader.resources.uColor[1] = 1;
 * shader.resources.uTexture = texture2.source;
 * @class
 * @memberof rendering
 */
export declare class Shader extends EventEmitter<{
	"destroy": Shader;
}> {
	/** An instance of the GPU program used by the WebGPU renderer */
	gpuProgram: GpuProgram;
	/** An instance of the GL program used by the WebGL renderer */
	glProgram: GlProgram;
	/**
	 * A number that uses two bits on whether the shader is compatible with the WebGL renderer and/or the WebGPU renderer.
	 * 0b00 - not compatible with either
	 * 0b01 - compatible with WebGL
	 * 0b10 - compatible with WebGPU
	 * This is automatically set based on if a {@link GlProgram} or {@link GpuProgram} is provided.
	 */
	readonly compatibleRenderers: number;
	/** */
	groups: Record<number, BindGroup>;
	/** A record of the resources used by the shader. */
	resources: Record<string, any>;
	/**
	 * A record of the uniform groups and resources used by the shader.
	 * This is used by WebGL renderer to sync uniform data.
	 * @internal
	 * @ignore
	 */
	_uniformBindMap: Record<number, Record<number, string>>;
	private readonly _ownedBindGroups;
	/**
	 * Fired after rendering finishes.
	 * @event rendering.Shader#destroy
	 */
	/**
	 * There are two ways to create a shader.
	 * one is to pass in resources which is a record of uniform groups and resources.
	 * another is to pass in groups which is a record of {@link BindGroup}s.
	 * this second method is really to make use of shared {@link BindGroup}s.
	 * For most cases you will want to use resources as they are easier to work with.
	 * USe Groups if you want to share {@link BindGroup}s between shaders.
	 * you cannot mix and match - either use resources or groups.
	 * @param {ShaderWithResourcesDescriptor} options - The options for the shader using ShaderWithResourcesDescriptor.
	 */
	constructor(options: ShaderWithResources);
	constructor(options: ShaderWithGroups);
	/**
	 * Sometimes a resource group will be provided later (for example global uniforms)
	 * In such cases, this method can be used to let the shader know about the group.
	 * @param name - the name of the resource group
	 * @param groupIndex - the index of the group (should match the webGPU shader group location)
	 * @param bindIndex - the index of the bind point (should match the webGPU shader bind point)
	 */
	addResource(name: string, groupIndex: number, bindIndex: number): void;
	private _buildResourceAccessor;
	/**
	 * Use to destroy the shader when its not longer needed.
	 * It will destroy the resources and remove listeners.
	 * @param destroyPrograms - if the programs should be destroyed as well.
	 * Make sure its not being used by other shaders!
	 */
	destroy(destroyPrograms?: boolean): void;
	/**
	 * A short hand function to create a shader based of a vertex and fragment shader.
	 * @param options
	 * @returns A shiny new PixiJS shader!
	 */
	static from(options: ShaderFromGroups): Shader;
	static from(options: ShaderFromResources): Shader;
}
export type BatchAction = "startBatch" | "renderBatch";
/**
 * A batch pool is used to store batches when they are not currently in use.
 * @memberof rendering
 */
export declare class Batch implements Instruction {
	renderPipeId: string;
	action: BatchAction;
	start: number;
	size: number;
	textures: BatchTextureArray;
	blendMode: BLEND_MODES;
	topology: Topology;
	canBundle: boolean;
	/**
	 * breaking rules slightly here in the name of performance..
	 * storing references to these bindgroups here is just faster for access!
	 * keeps a reference to the GPU bind group to set when rendering this batch for WebGPU. Will be null is using WebGL.
	 */
	gpuBindGroup: GPUBindGroup;
	/**
	 * breaking rules slightly here in the name of performance..
	 * storing references to these bindgroups here is just faster for access!
	 * keeps a reference to the bind group to set when rendering this batch for WebGPU. Will be null if using WebGl.
	 */
	bindGroup: BindGroup;
	batcher: Batcher;
	destroy(): void;
}
/**
 * Represents an element that can be batched for rendering.
 * @interface
 * @memberof rendering
 */
export interface BatchableElement {
	/**
	 * The name of the batcher to use. Must be registered.
	 * @type {string}
	 */
	batcherName: string;
	/**
	 * The texture to be used for rendering.
	 * @type {Texture}
	 */
	texture: Texture;
	/**
	 * The blend mode to be applied.
	 * @type {BLEND_MODES}
	 */
	blendMode: BLEND_MODES;
	/**
	 * The size of the index data.
	 * @type {number}
	 */
	indexSize: number;
	/**
	 * The size of the attribute data.
	 * @type {number}
	 */
	attributeSize: number;
	/**
	 * The topology to be used for rendering.
	 * @type {Topology}
	 */
	topology: Topology;
	/**
	 * Whether the element should be packed as a quad for better performance.
	 * @type {boolean}
	 */
	packAsQuad: boolean;
	/**
	 * The texture ID, stored for efficient updating.
	 * @type {number}
	 * @private
	 */
	_textureId: number;
	/**
	 * The starting position in the attribute buffer.
	 * @type {number}
	 * @private
	 */
	_attributeStart: number;
	/**
	 * The starting position in the index buffer.
	 * @type {number}
	 * @private
	 */
	_indexStart: number;
	/**
	 * Reference to the batcher.
	 * @type {Batcher}
	 * @private
	 */
	_batcher: Batcher;
	/**
	 * Reference to the batch.
	 * @type {Batch}
	 * @private
	 */
	_batch: Batch;
}
/**
 * Represents a batchable quad element.
 * @extends BatchableElement
 * @memberof rendering
 */
export interface BatchableQuadElement extends BatchableElement {
	/**
	 * Indicates that this element should be packed as a quad.
	 * @type {true}
	 */
	packAsQuad: true;
	/**
	 * The size of the attribute data for this quad element.
	 * @type {4}
	 */
	attributeSize: 4;
	/*